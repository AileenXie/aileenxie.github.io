<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aileen&#39;s Blog on Aileen&#39;s Blog</title>
    <link>https://aileenxie.github.io/</link>
    <description>Recent content in Aileen&#39;s Blog on Aileen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ch-cn</language>
    <lastBuildDate>Tue, 27 Aug 2019 08:50:51 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Matlab配置Xcode编译</title>
      <link>https://aileenxie.github.io/2019/11xcode/</link>
      <pubDate>Tue, 27 Aug 2019 08:50:51 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2019/11xcode/</guid>
      <description>

&lt;p&gt;Matlab使用时经常需要编译一些其他语言的文件来调用，这需要相应的编译器来完成编译过程。Mac上编译C/C++可以选用Xcode。&lt;/p&gt;

&lt;h1 id=&#34;安装xcode&#34;&gt;安装Xcode&lt;/h1&gt;

&lt;p&gt;Appstores 就能直接下载安装Xcode&lt;/p&gt;

&lt;h1 id=&#34;安装command-line-tools&#34;&gt;安装command line tools&lt;/h1&gt;

&lt;p&gt;在终端上输入：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;xcode-select --install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后会有弹窗提示安装，跟着向导一步步完成安装。&lt;/p&gt;

&lt;p&gt;确认安装成功的方法是：打开Xcode -&amp;gt; New -&amp;gt; Project，看到Command line tools。
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8mN6gy1g6dylnelzlj314p0u0n27.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;打开matlab项目，运行命令，看是否成功检测到编译器。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mex -setup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;h1 id=&#34;还不成功&#34;&gt;还不成功 ？&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;可能需要进行的操作&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我在Matlab R2018a和Xcode v10.1环境下，安装完Command line tools之后再运行&lt;code&gt;mex -setup&lt;/code&gt;就能&lt;strong&gt;成功&lt;/strong&gt;找到编译器了！但是我看其他人有碰到需要更改配置文件的步骤，我还是记录一下，以便以后遇到问题多一条思路。具体方法是替换Matlab的启动和配置文件mexopts.sh和clang_maci64.xml里MacOSX版本号。&lt;/p&gt;

&lt;h2 id=&#34;查看本机macosx-sdk版本号&#34;&gt;查看本机MacOSX SDK版本号&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在&lt;code&gt;/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs&lt;/code&gt;中查看自己的版本号：
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6gy1g6dz5p7rx0j311k0nmwhp.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;或者终端运行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;xcrun -sdk macosx --show-sdk-path
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;或&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;xcrun -sdk macosx --show-sdk-version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;更改mexopts-sh文件&#34;&gt;更改mexopts.sh文件&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;打开Matlab，命令行运行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;edit ([matlabroot &#39;/bin/mexopts.sh&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打开mexopts.sh文件，以防万一提前备份一下该文件。把该文件中所有macosx10.x更改为本机MacOS版本号。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;让更改生效：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd (matlabroot) 
cd bin 
mex -setup 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输入1，然后回车，输入y，回车。 详见&lt;a href=&#34;https://blog.csdn.net/bingshanqiao/article/details/48948065?utm_source=blogxgwz6&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;CSDN博文&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;更改clang-maci64-xml文件&#34;&gt;更改clang_maci64.xml文件&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;打开Matlab，命令行运行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;edit ([matlabroot &#39;/bin/maci64/mexopts/clang_maci64.xml&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打开clang_maci64.xml文件（如果是编译C++，相应更改clang++_maci64.xml文件），以防万一提前备份一下该文件。更改方法&lt;a href=&#34;https://blog.csdn.net/sinat_38068956/article/details/80326877&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;CSDN博文&lt;/a&gt;，&lt;a href=&#34;https://ww2.mathworks.cn/matlabcentral/answers/243868-mex-can-t-find-compiler-after-xcode-7-update-r2015b?#comment_407066&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;MathWorks社区&lt;/a&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tips: 我目前用的是Matlab R2018a，我打开这个文件已经和之前文章说要更改的文件不一样了，不知道还有没有更改这个文件的需要，反正我用的Xcode v10.1 (10B61)没改一切正常。
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8mN6gy1g6e0nvirr3j316g0hi45c.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;看到还有说Xcode没有接受协议也会有问题，放个&lt;a href=&#34;https://www.jianshu.com/p/35463964a361&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;简书文链&lt;/a&gt;结尾处有讲到这个问题。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matlab下Libsvm安装使用</title>
      <link>https://aileenxie.github.io/2019/10libsvm/</link>
      <pubDate>Mon, 26 Aug 2019 23:34:14 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2019/10libsvm/</guid>
      <description>

&lt;h1 id=&#34;下载&#34;&gt;下载&lt;/h1&gt;

&lt;p&gt;从github上拉取源码到你想放的目录（我放在matlab工作目录/toolbox/），源码地址：&lt;a href=&#34;https://github.com/cjlin1/libsvm&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;GitHub - cjlin1/libsvm&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&#34;编译&#34;&gt;编译&lt;/h1&gt;

&lt;p&gt;文件windows/目录下有预先编译好的&lt;strong&gt;libsvmread.mexw64&lt;/strong&gt;、&lt;strong&gt;libsvmwrite.mexw64&lt;/strong&gt;、&lt;strong&gt;svmtrain.mexw64&lt;/strong&gt;、&lt;strong&gt;svmpredict.mexw64&lt;/strong&gt;文件。如果是windows 64位下的matlab可以直接使用这些编译文件。&lt;/p&gt;

&lt;p&gt;我的是mac版的matlab,需要重新编译相应的&lt;code&gt;.mexmaci64&lt;/code&gt;文件，windows32的则是编译出&lt;code&gt;.mexw32&lt;/code&gt;文件。具体来说：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;先确保电脑装了C/C++编译器，我电脑本身装了Xcode自带Clang，不需要再装编译器了，没装的随便装个编译器再进行下面的步骤（参考&lt;a href=&#34;https://aileenxie.com/2019/11xcode/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Matlab配置Xcode编译&lt;/a&gt;）。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在Matlab中进入Libsvm根目录下的matlab目录（如:toolbox/libsvm-3.23/matlab），在命令窗口输入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;mex –setup
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Matlab会提示你选择编译mex文件的C/C++编译器，就选择一个已安装的编译器，如Xcode with Clang。之后Matlab会提示确认选择的编译器，输入y进行确认。
&lt;img src=&#34;https://aileenxie.github.io/img/10libsvm_26.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;输入以下命令进行编译:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;make
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译成功后，当前目录下会出现4个后缀为mexmaci64的文件。（tips:Matlab或VC版本过低可能会导致编译失败，建议使用最新的版本）。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;把编译出的这4个文件加入matlab的路径以便之后的调用。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;重命名&#34;&gt;重命名&lt;/h1&gt;

&lt;p&gt;编译好后，由于产生的文件svmtrain和svmpredict与Matlab中自带有SVM的工具箱中的函数同名，为了避免调用不了，可以把这两个文件的编译文件重命名一下。我是重命名成了libsvmtrain和libsvmpredict，然后用新的名字来调用函数即可。&lt;/p&gt;

&lt;h1 id=&#34;基本使用&#34;&gt;基本使用&lt;/h1&gt;

&lt;h2 id=&#34;libsvmread函数&#34;&gt;libsvmread函数&lt;/h2&gt;

&lt;p&gt;用来读取以LIBSVM格式存储的数据文件。libsvm包根目录里有个示例数据文件&lt;code&gt;heart-scale&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;[label_vector, instance_matrix] = libsvmread(&amp;quot;heart-scale.txt&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数输出：&lt;code&gt;label_vector&lt;/code&gt;是数据标签，&lt;code&gt;instance_matrix&lt;/code&gt;是数据矩阵。&lt;/p&gt;

&lt;h2 id=&#34;libsvmwrite函数&#34;&gt;libsvmwrite函数&lt;/h2&gt;

&lt;p&gt;用来把matlab数据矩阵和标签存成LIBSVM格式数据文件data.txt:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;libsvmwrite(&amp;quot;data.txt&amp;quot;, label_vector, instance_matrix]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;libsvmtrain函数&#34;&gt;libsvmtrain函数&lt;/h2&gt;

&lt;p&gt;用来训练SVM分类器模型，具体参数如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;model = svmtrain(label,inst,Parameters)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：&lt;font color=#0099ff&gt;model.Paramaters = [-s,-t,-d,-g,-r]&lt;/font&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;【输入】数据标签+数据矩阵+&lt;strong&gt;Parameters&lt;/strong&gt;: 一个5 x 1的向量，从上到下依次表示：&lt;/p&gt;

&lt;p&gt;　　　-s SVM类型（默认0）:&lt;/p&gt;

&lt;p&gt;　　　　　　　0 &amp;ndash; C-SVC,&lt;/p&gt;

&lt;p&gt;　　　　　　　1 &amp;ndash; nu-SVC,&lt;/p&gt;

&lt;p&gt;　　　　　　　2 &amp;ndash; one-class SVM,&lt;/p&gt;

&lt;p&gt;　　　　　　　3 &amp;ndash; epsilon-SVR&lt;/p&gt;

&lt;p&gt;　　　-t 核函数类型（默认2）:　　&lt;/p&gt;

&lt;p&gt;　　　　　　　0 &amp;ndash; linear: u&amp;rsquo;*v,&lt;/p&gt;

&lt;p&gt;　　　　　　　1 &amp;ndash; polynomial: (gamma*u&amp;rsquo;*v + coef0)^degree,&lt;/p&gt;

&lt;p&gt;　　　　　　　2 &amp;ndash; radial basis function: exp(-gamma*|u-v|^2),&lt;/p&gt;

&lt;p&gt;　　　　　　　3 &amp;ndash; sigmoid: tanh(gamma*u&amp;rsquo;*v + coef0)&lt;/p&gt;

&lt;p&gt;　　　-d 核函数中的degree设置(针对多项式核函数)(默认3)；&lt;/p&gt;

&lt;p&gt;　　　-g 核函数中的r(gamma）函数设置(针对多项式/rbf/sigmoid核函数) (默认类别数目的倒数)；&lt;/p&gt;

&lt;p&gt;　　　-r 核函数中的coef0设置(针对多项式/sigmoid核函数)(默认0)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;【输出】&lt;strong&gt;&lt;em&gt;训练出来的model&lt;/em&gt;&lt;/strong&gt;：包含11个字段的struct&lt;/p&gt;

&lt;p&gt;　　　　Parameters:5x1参数向量（如上）&lt;/p&gt;

&lt;p&gt;　　　　nr_class: 表示数据集中有多少类别，比如二分类时这个值即为2。&lt;/p&gt;

&lt;p&gt;　　　　totalSV: 表示支持向量的总数。&lt;/p&gt;

&lt;p&gt;　　　　rho: 决策函数wx+b中的常数项的相反数（-b）。&lt;/p&gt;

&lt;p&gt;　　　　Label: 表示数据集中类别的标签，比如二分类常见的1和-1。&lt;/p&gt;

&lt;p&gt;　　　　ProbA: 使用-b参数时用于概率估计的数值，否则为空。&lt;/p&gt;

&lt;p&gt;　　　　ProbB: 使用-b参数时用于概率估计的数值，否则为空。&lt;/p&gt;

&lt;p&gt;　　　　nSV: 表示每类样本的支持向量的数目，和Label的类别标签对应。如Label=[1; -1],nSV=[63; 67]，则标签为1的样本有63个支持向量，标签为-1的有67个。&lt;/p&gt;

&lt;p&gt;　　　　sv_coef: 表示每个支持向量在决策函数中的系数。&lt;/p&gt;

&lt;p&gt;　　　　SVs: 表示所有的支持向量，如果特征是n维的，支持向量一共有m个，则为m x n的稀疏矩阵。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;libsvmpredict函数&#34;&gt;libsvmpredict函数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;[predict,accuracy,probabilityEstimates] = svmpredict(label,inst,model)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;【输入】数据标签+数据矩阵+model&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;【输出】&lt;strong&gt;&lt;em&gt;返回值&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;　　　　predicted_label：第一个返回值，表示样本的预测类标号。&lt;/p&gt;

&lt;p&gt;　　　　accuracy：第二个返回值，一个3 x 1的数组，表示分类的&lt;code&gt;正确率&lt;/code&gt;、&lt;code&gt;回归的均方根误差&lt;/code&gt;、&lt;code&gt;回归的平方相关系数&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;　　　　decision_values/prob_estimates：第三个返回值，一个矩阵包含&lt;code&gt;决策的值&lt;/code&gt;或者&lt;code&gt;概率估计&lt;/code&gt;。对于n个预测样本、k类的问题，如果指定“-b 1”参数，则n x k的矩阵，每一行表示这个样本分别属于每一个类别的概率；如果没有指定“-b 1”参数，则为n x k*(k-1)/2的矩阵，每一行表示k(k-1)/2个二分类SVM的预测结果。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;示例&#34;&gt;示例&lt;/h1&gt;

&lt;p&gt;用libsvm包根目录里的示例数据文件&lt;code&gt;heart-scale&lt;/code&gt;为例，运行以下脚本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;[heart_scale_label, heart_scale_inst] = libsvmread(&#39;heart_scale&#39;);
model = libsvmtrain(heart_scale_label, heart_scale_inst, &#39;-c 1 -g 0.07&#39;);
[predict_label, accuracy, dec_values] = libsvmpredict(heart_scale_label, heart_scale_inst, model);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到训练模型：
&lt;img src=&#34;https://aileenxie.github.io/img/10libsvm_132.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;预测结果：
&lt;img src=&#34;https://aileenxie.github.io/img/10libsvm_135.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;*
optimization finished, #iter = 134
nu = 0.433785
obj = -101.855060, rho = 0.426412
nSV = 130, nBSV = 107
Total nSV = 130
Accuracy = 86.6667% (234/270) (classification)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>研一总结</title>
      <link>https://aileenxie.github.io/2019/09essay/</link>
      <pubDate>Sat, 24 Aug 2019 12:56:56 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2019/09essay/</guid>
      <description>

&lt;script type=&#34;text/javascript&#34; src=&#34;https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt;

&lt;p&gt;忙完了论文，在暑假的最后两周才真正开始了暑期模式。&lt;/p&gt;

&lt;p&gt;研一这一年上完了所有课程从0开始完成了一篇论文并投稿，成长挺大的。博客空了很久没更，趁这两周把之前的零碎知识点整理一下放上博客。这篇作为研一一年的学习记录。&lt;/p&gt;

&lt;h2 id=&#34;课程&#34;&gt;课程&lt;/h2&gt;

&lt;p&gt;除了统修的政治课（中特社、辩证法）和英语课，专业相关课程及结课作业统计如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;【算法设计与分析】：考试&lt;/li&gt;
&lt;li&gt;【大规模非线性规划】：论文汇报&lt;a href=&#34;http://proceedings.mlr.press/v80/gu18a/gu18a.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines&lt;/a&gt;新的异步随机零阶算法（AsySZO+）；&lt;/li&gt;
&lt;li&gt;【图形图像处理技术】：论文汇报&lt;a href=&#34;https://arxiv.org/abs/1804.08328&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Taskonomy: Disentangling Task Transfer Learning&lt;/a&gt;；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【数据管理系统实现】：论文汇报&lt;a href=&#34;http://cidrdb.org/cidr2015/Papers/CIDR15_Paper28.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Impala: A Modern, Open-Source SQL Engine for Hadoop&lt;/a&gt;，论文复现&lt;a href=&#34;https://arxiv.org/abs/1711.08330&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Adaptive Cardinality Estimation&lt;/a&gt;自适应查询优化aqo；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【机器学习】：论文汇报&lt;a href=&#34;https://arxiv.org/abs/1803.06333&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Snap ML: A Hierarchical Framework for Machine Learning&lt;/a&gt;；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【专业外语】：论文汇报——密码学新方向；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【云计算安全】：论文汇报&lt;a href=&#34;https://ieeexplore.ieee.org/document/8462336&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Multi-Kernel, Deep Neural Network and Hybrid Models for Privacy Preserving Machine Learning&lt;/a&gt;用于隐私保护机器学习的多核，深层神经网络和混合模型；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【计算机视觉】：深度估计方向论文总结，图像检测方向综述，论文复现 RetinaNet。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;论文&#34;&gt;论文&lt;/h2&gt;

&lt;p&gt;论文研究的是传统机器学习的特征工程 &amp;amp; 优化问题，记录一下整个过程。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;最初参考的文献是以下四篇:①&lt;a href=&#34;https://arxiv.org/pdf/1310.1969.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Statistical Estimation and Testing via the Sorted l1 Norm&lt;/a&gt;, ②&lt;a href=&#34;https://arxiv.org/abs/1511.09078&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Group SLOPE - adaptive selection of groups of predictors&lt;/a&gt;, ③&lt;a href=&#34;https://ieeexplore.ieee.org/document/7104157?arnumber=7104157&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Discriminative Structured Feature Engineering for Macroscale Brain Connectomes&lt;/a&gt;, ④&lt;a href=&#34;http://proceedings.mlr.press/v37/luo15.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Support Matrix Machines&lt;/a&gt;。涉及到统计学的假设检验、多重假设检验矫正（BHq过程），这些知识点我在之前的博客有整理过。前两篇论文则是借鉴这些统计学方法，提出了针对线性回归的新的机器学习方法。后两篇则是针对矩阵数据的结构性特征工程方法。在反复研读这几篇文章之后，我对其中的思路和推导都有一定了解后，又陆续看了更多的相关论文，加深认识，进而提出了新的方法，并对该方法的解析解进行了推导。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;接着就是代码阶段，用的是matlab，之前大学短暂用过，但是长时间没用几乎是重新学习。代码是在导师之前一篇论文中用的一套代码上写的，matlab的代码基本没用框架，求梯度、近端梯度（Proximal Gradient, PG））迭代训练、收敛判断、参数选择（AIC、Crossvalidation）、生成模拟数据&amp;hellip;一个一个模块纯靠手码出来的，这部分感觉收获很大，比起用框架，更清楚地了解了每一个模块的详细逻辑。实验在模拟实验跑得差不多之后，再上真实数据。不过因为调参没经验，很长一段时间不得要领，调实验这一阶段耗时较久。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;实验调得差不多就开始写论文了，用的mactex+sublime套一个IEEE的框架，从Method部分开始写起。一开始还担心参考文献太少，后来写到related work部分，因为要理顺思路，自然而然看了很多文章，参考文献渐渐多了起来。实验部分除了本来的几个图和表，导师给了两个matlab的可视化工具让我自己研究，一个是&lt;a href=&#34;https://www.nitrc.org/projects/bnv/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;BrainNet Viewer&lt;/a&gt;（重建脑部ROI 3D连接图的，因为论文做的是脑连接体相关的），一个是&lt;a href=&#34;https://github.com/paul-kassebaum-mathworks/circularGraph&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;CircularGraph&lt;/a&gt;（描述连接、相关、小世界网络）。第二个工具因为还不能完全满足理想环形图外观，还额外研究了一下怎么用matlab画圆环、打标注。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;调实验和写论文后期基本是重叠的，论文也是改到最后一刻，直到交稿还有不满意的地方。另外值得一提的是，投的会议截稿时间不是UTC，而是会议当地的时间，跟我们差了19个时区，一开始还弄错了，后来发现还有时间😂。截稿前论文可以重复提交，以最后一次提交为准。截稿后就是漫长等待了。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还有一周多的时间开学，开学之后会接触新的领域。新的学期要保持更博的节奏，有时间多刷刷题，看看书，珍惜最后在学校的一年半时光吧。加油！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI线稿上色——Style2paints</title>
      <link>https://aileenxie.github.io/2019/08style2paints/</link>
      <pubDate>Thu, 31 Jan 2019 21:03:40 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2019/08style2paints/</guid>
      <description>

&lt;p&gt;快期末的时候喜得一个wacon的板子，很久没画画了，业务生疏还有点不习惯，画得很慢。偶然被推荐一个很有意思的开源项目Style2paints（&lt;a href=&#34;https://github.com/lllyasviel/style2paints&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;源码地址&lt;/a&gt;），一个AI线稿上色工具，可以快速地进行线稿的智能上色。&lt;/p&gt;

&lt;p&gt;但是很不巧，1月18号Style2paints-V4版本的服务器就因为经费原因关闭了，我看到这个项目的时候已经无法在线访问了，只好尝试本地搭环境启动。目前代码只开源了V3版本，看官方描述V3和V4差别还蛮大的。V4是模拟人工上色流程对线稿进行分层上色，输出也是PSD分层的文件，V3输出的是单层的图片，操作也不太一样。&lt;/p&gt;

&lt;p&gt;V3页面（自截图）：
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;V4页面（官方介绍视频里截的）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里记录一下mac上Style2paints-V3本地搭建的过程。&lt;/p&gt;

&lt;h2 id=&#34;1-python环境&#34;&gt;1. Python环境&lt;/h2&gt;

&lt;p&gt;首先要准备python3的环境，mac下的安装可以参考之前的&lt;a href=&#34;https://aileenxie.com/2018/06python_mac/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;文章&lt;/a&gt;，用homebrew直接安装。&lt;/p&gt;

&lt;h2 id=&#34;2-依赖包&#34;&gt;2. 依赖包&lt;/h2&gt;

&lt;p&gt;这里没有用gpu版本的tensorflow，安装以下依赖包：&lt;/p&gt;

&lt;p&gt;pip3 install tensorflow (安装需要翻墙，全局模式命令行安装)&lt;/p&gt;

&lt;p&gt;pip3 install keras&lt;/p&gt;

&lt;p&gt;pip3 install bottle&lt;/p&gt;

&lt;p&gt;pip3 install gevent&lt;/p&gt;

&lt;p&gt;pip3 install h5py&lt;/p&gt;

&lt;p&gt;pip3 install opencv-python&lt;/p&gt;

&lt;p&gt;pip3 install scikit-image&lt;/p&gt;

&lt;p&gt;pip3 install paste&lt;/p&gt;

&lt;h2 id=&#34;3-源码运行&#34;&gt;3.源码运行&lt;/h2&gt;

&lt;p&gt;拉取源码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/lllyasviel/style2paints
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到V3目录下执行server/server.py文件。正常运行的话可以直接本地打开 &lt;a href=&#34;http://127.0.0.1:80/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://127.0.0.1:80/&lt;/a&gt; 就能看到界面。但是我运行的过程中有以下几点异常。&lt;/p&gt;

&lt;h2 id=&#34;4-q-tensorflow编译警告&#34;&gt;4. Q:Tensorflow编译警告&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;原因是CPU支持AVX扩展(高级矢量扩展)，但是默认安装（pip install）的TensorFlow版本不支持使用扩展。其实用了扩展CPU也比GPU慢得多。解决办法有两个：&lt;/p&gt;

&lt;p&gt;1）忽略警告，直接在server.py代码中加入：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2)源码编译tensorflow
从针对CPU优化的源去构建tensorflow，不仅可以去掉这个警告，还能提高CPU下的tensorflow的性能。具体参考tensorflow的&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/8037&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;issue8037&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;5-q-报错找不到文件&#34;&gt;5. Q:报错找不到文件&lt;/h2&gt;

&lt;p&gt;拉的源码里少了几个文件：
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_65.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1fWi4wmNj-xr-nCzuWMsN2rcm0249_Aem&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;文件云盘链接&lt;/a&gt;,
需要下载放到V3/server/目录下，再重新运行server.py文件，访问本地 &lt;a href=&#34;http://127.0.0.1:80/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://127.0.0.1:80/&lt;/a&gt; ，就可以看到这个页面：
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_69.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;6-简单教程&#34;&gt;6. 简单教程&lt;/h2&gt;

&lt;p&gt;我是直接看的作者写的一篇&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36560034&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;速成教程&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;总体体验还是很不错的，虽然上色不一定如自己手工上色更能随心所欲，但是够快啊，我CPU跑的上色差不多十来秒。简单试了几个图。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;网上找的线稿上色：
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_77.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_79.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自己的图重上色：
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_82.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;第一个是原图，第二个是去色的底图，后两个是重上色效果。
&lt;img src=&#34;https://aileenxie.github.io/img/08style2paints_84.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>论文书写工具准备——MacTeX</title>
      <link>https://aileenxie.github.io/2018/07use_mactex/</link>
      <pubDate>Mon, 19 Nov 2018 20:00:38 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/07use_mactex/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;TEX：斯坦福大学的教授Donald E.Knuth开发的一个功能强大的幕后排版系统。它是一种语言，类似于Java和C之类的计算机语言，但是它是为简单的排版操作设计的；&lt;/li&gt;
&lt;li&gt;LaTeX：是TEX的众多宏集之一，是由Leslie Lamport编写的。将一些常用到的功能整合为文档类型中的设置，简化了TEX排版的工作量及难度；&lt;/li&gt;
&lt;li&gt;CTEX：利用TEX排版系统的CTEX中文套装的简称。它集成了编辑器 、WinEdt和 PostScript处理软件 Ghostscript 和 GSview 等主要工具。&lt;/li&gt;
&lt;li&gt;TeXLiv：是一个TeX发行版，它是一组程序的集合，主要作用就是将你写的TeX代码进行解析排版输出成PS或者PDF。“TeX发行版相对于TeX语言”大致可以理解为“C语言编译器(如GCC或Clang)相对于C语言”的关系；&lt;/li&gt;
&lt;li&gt;MacTeX：是Mac版的TeXLive。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文MacTeX搭配Sublime(编辑器)和Skim(PDF阅读器)食用。&lt;/p&gt;

&lt;h2 id=&#34;mactex安装&#34;&gt;MacTeX安装&lt;/h2&gt;

&lt;p&gt;官网：&lt;a href=&#34;http://tug.org/mactex/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://tug.org/mactex/&lt;/a&gt;
安装好后会看到一串东西（我把它们放到了同一个文件夹里）：
&lt;img src=&#34;https://aileenxie.github.io/img/07use_mactex_20.jpg&#34; alt=&#34;&#34; /&gt;
TeXShop：它是一个官配的编辑器，比较简单。我们这里用Sublime取代。&lt;/p&gt;

&lt;h2 id=&#34;sublime和skim安装&#34;&gt;Sublime和Skim安装&lt;/h2&gt;

&lt;p&gt;Sublime官网：&lt;a href=&#34;https://www.sublimetext.com/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.sublimetext.com/&lt;/a&gt;
Skim官网：&lt;a href=&#34;https://skim-app.sourceforge.io/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://skim-app.sourceforge.io/&lt;/a&gt;
图标长这样：
&lt;img src=&#34;https://aileenxie.github.io/img/07use_mactex_27.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;环境配置&#34;&gt;环境配置&lt;/h2&gt;

&lt;h3 id=&#34;sublime配置&#34;&gt;Sublime配置&lt;/h3&gt;

&lt;p&gt;打开Sublime，我们需要安装LaTeX相关插件才能更好地使用，插件从&lt;a href=&#34;https://packagecontrol.io/installation&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Package Control官网&lt;/a&gt;下载，步骤如下：
1. 进入Sublime的终端：&lt;code&gt;ctrl+ [esc下面那个顿号]&lt;/code&gt; 或 &lt;code&gt;View &amp;gt; Show Consoles&lt;/code&gt;
2. 从&lt;a href=&#34;https://packagecontrol.io/installation&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Package Control官网&lt;/a&gt;复制灰色代码段输入Sublime的终端并回车运行，注意对应的版本号：
&lt;img src=&#34;https://aileenxie.github.io/img/07use_mactex_34.jpg&#34; alt=&#34;&#34; /&gt;
3. 等待安装完成后，退出重启Sublime;
4. 安装插件包：&lt;code&gt;Command+Shift+P&lt;/code&gt;或&lt;code&gt;Tools &amp;gt; Command Palette…&lt;/code&gt;&amp;mdash;&amp;gt;输入&amp;rdquo;install package&amp;rdquo;回车&amp;mdash;&amp;gt;输入“LaTeX Tools”，找到这一项并点击安装。完成后重启Sublime。
5. 新建一个文件test.tex(一定要有后缀.tex!!!)，复制以下内容进去：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;\documentclass{article}
\begin{document}
Hello LaTeX
\end{document}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可看到Latex格式文件有彩色样式，完成！&lt;/p&gt;

&lt;h3 id=&#34;skim配置&#34;&gt;Skim配置&lt;/h3&gt;

&lt;p&gt;打开Skim后，&lt;code&gt;Command+,&lt;/code&gt;或&lt;code&gt;Skim &amp;gt; 选项（performance）&lt;/code&gt;&amp;mdash;&amp;gt;点到【同步（sync）】页&amp;mdash;&amp;gt;设置Preset为Sublime(不知道为什么我这边没有Sublime3选项，选了2也可行)
&lt;img src=&#34;https://aileenxie.github.io/img/07use_mactex_48.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;测试环境&#34;&gt;测试环境&lt;/h3&gt;

&lt;p&gt;回到Sublime刚才新建的test.tex文件，&lt;code&gt;Command+B&lt;/code&gt;或&lt;code&gt;Tools &amp;gt; Build&lt;/code&gt;编译tex文件，顺利的话，Skim会自动弹出PDF文件预览窗口。环境搭建成功！&lt;/p&gt;

&lt;p&gt;至此整个环境就搭完了，具体怎么用mactex写出漂亮的文章和公式参考&lt;a href=&#34;http://www.voidcn.com/article/p-gkwzgucc-bru.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;LaTeX快速入门：一文浅谈TeX排版语法&lt;/a&gt;，还有些小技巧我会之后总结一篇文章。待续。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/cs24k1993/article/details/78082437&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;参考文章1&lt;/a&gt;
&lt;a href=&#34;https://www.jianshu.com/p/b1e3b029ded5&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;参考文章2&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mac下安装Python3</title>
      <link>https://aileenxie.github.io/2018/06python_mac/</link>
      <pubDate>Mon, 19 Nov 2018 20:00:13 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/06python_mac/</guid>
      <description>

&lt;!-- &lt;meta name=&#34;referrer&#34; content=&#34;no-referrer&#34; /&gt; --&gt;

&lt;p&gt;简单记录mac下Python3安装步骤。&lt;/p&gt;

&lt;h2 id=&#34;安装python3&#34;&gt;安装Python3&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;应先安装C编译器。最快的方式是运行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;xcode-select --install 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;来安装Xcode命令行工具。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装一个包管理工具Homebrew&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ /usr/bin/ruby -e &amp;quot; $ (curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;插入PATH（在~/.profile文件末尾加）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=/usr/local/bin:/usr/local/sbin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;(source .profile 一下使之生效)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装Python3&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install python
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查看&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 --version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确定pip是否安装&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若未安装&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m ensurepip --default-pip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pip的使用详见&lt;a href=&#34;https://packaging.python.org/tutorials/installing-packages/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;相关参考文档&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>FDR与BH过程</title>
      <link>https://aileenxie.github.io/2018/05fdr/</link>
      <pubDate>Mon, 19 Nov 2018 19:59:46 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/05fdr/</guid>
      <description>

&lt;!-- &lt;meta name=&#34;referrer&#34; content=&#34;no-referrer&#34; /&gt; --&gt;

&lt;!-- &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&#34;&gt;&lt;/script&gt; --&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt;

&lt;p&gt;最近导师让看的paper里用到了FDR的理念，借这个机会把FDR相关概念理解了一遍，整理出来。&lt;/p&gt;

&lt;h2 id=&#34;统计相关基础知识&#34;&gt;统计相关基础知识&lt;/h2&gt;

&lt;h3 id=&#34;假设检验&#34;&gt;假设检验&lt;/h3&gt;

&lt;p&gt;假设检验的基本思想是&lt;strong&gt;小概率反证法&lt;/strong&gt;思想。小概率思想是指小概率事件（P&amp;lt;0.01或P&amp;lt;0.05）在一次试验中基本上不会发生。反证法思想是先提出假设(检验假设H0)，再用适当的统计方法确定假设成立的可能性大小，如可能性小，则认为假设不成立，若可能性大，则还不能认为假设不成立。&lt;/p&gt;

&lt;h3 id=&#34;p值&#34;&gt;P值&lt;/h3&gt;

&lt;p&gt;即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法（&lt;a href=&#34;https://aileenxie.github.io/2018/04txf/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;t检验，Z检验，卡方检验，F检验&lt;/a&gt;等等）所得到的P 值，一般以 P&amp;lt;0.05 为有统计学差异， P&amp;lt;0.01 为有显著统计学差异，P&amp;lt;0.001 为有极其显著的统计学差异。其含义是样本间的差异由抽样误差所致的概率小于0.05 、0.01、0.001。实际上，P值不能赋予数据任何重要性，只能说明某事件发生的几率。&lt;/p&gt;

&lt;p&gt;给定显著性水准alpha时，可得出对应的拒绝域；根据当前试验，可以计算出P值。当P值越小时，表示此时试验得到的统计量t越落在拒绝域。因此基于P值的结果等价于基于t值的结果。因此，&lt;strong&gt;P值越小，拒绝原假设的信心越大&lt;/strong&gt;。
&lt;img src=&#34;https://aileenxie.github.io/img/05fdr_23.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;原假设-h0-备择假设-h1&#34;&gt;原假设(H0) &amp;amp; 备择假设(H1)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;原假设（又叫零假设）是在一次试验中有绝对优势出现的事件&lt;/li&gt;
&lt;li&gt;备择假设（又叫备选假设、对立假设）在一次试验中不易发生(或几乎不可能发生)的事件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，在进行单侧检验时，最好把&lt;strong&gt;原假设&lt;/strong&gt;取为预想结果的&lt;strong&gt;反面&lt;/strong&gt;，即把希望证明的命题放在备择假设上。&lt;/p&gt;

&lt;h3 id=&#34;一类错误-二类错误&#34;&gt;一类错误 &amp;amp; 二类错误&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;第一类错误（假阳性）又称“Ⅰ型错误”、“拒真错误”，是指拒绝了实际上成立的、正确的假设，为“弃真”的错误，其概率通常用α（显著性水平）表示。&lt;/li&gt;
&lt;li&gt;第二类错误（假阴性）又称“口错误”、“纳伪错误”、“第Ⅱ型错误”。假设检验术语。与“第一类错误”相对。在零假设H0本来不真的情况下，检验统计量的观测值落入接受域而接受Ho而犯的错误。用字母β表示。
&lt;img src=&#34;https://aileenxie.github.io/img/05fdr_35.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;举个栗子&#34;&gt;🌰举个栗子&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;为了帮助理解，我编了个例子。&lt;/p&gt;

&lt;p&gt;【例子一】小白五感超群，他自称能够辨别一杯白咖啡是先倒入的牛奶还是先倒入的咖啡。为了验证这个说法，我们进行一组实验。
实验内容：放5杯咖啡，让小白品尝并说出每一杯咖啡是先加奶还是先加咖啡。靠猜答对5杯咖啡的概率\(P=(\frac{1}{2})^{5}\approx 0.031=3.1\%\)。假设显著性水平（阈值）设为5%：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;H0：小白辨别咖啡是靠猜的&lt;/li&gt;
&lt;li&gt;H1：小白辨别咖啡不是靠猜的（即小白有能力辨别）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;试验结果是5杯咖啡都被成功辨别。此事件P = 3.1% &amp;lt; 5%，故可以拒绝原假设，承认小白能够辨别白咖啡。但有3.1%的可能判断错误（I类错误），因为有3.1%的可能小白就是靠猜的。可以通过增加咖啡杯数来降低P值（靠猜全答对的难度越来越高），这样拒绝原假设的自信度就越高。&lt;/p&gt;

&lt;h2 id=&#34;多重假设检验校正&#34;&gt;多重假设检验校正&lt;/h2&gt;

&lt;p&gt;多次检验导致的大量假阳性：如果检验一次，犯错的概率是5%；检验10000次，犯错的次数就是500次，即额外多出了500次差异的结论（即
使实际没有差异）。&lt;/p&gt;

&lt;p&gt;结合例子🌰说就是：假设一人品咖啡靠猜对概率是5%，10000个人来品咖啡就会有500个人靠猜来答对，如果阈值还设为5%的话，这500个人都被判为是有能力辨别咖啡能力的人，但是明明他们都是靠猜的啊！！！那么这就有500个一类错误。&lt;/p&gt;

&lt;p&gt;所以当同一个数据集有n次（n&amp;gt;=2）假设检验时，要做多重假设检验校正。这里讨论Bonferroni校正和FDR校正两种P值校正方法。&lt;/p&gt;

&lt;h3 id=&#34;bonferroni-最简单严厉的方法&#34;&gt;Bonferroni —— “最简单严厉的方法”&lt;/h3&gt;

&lt;p&gt;如果检验1000次，我们就将阈值设定为5%/1000=0.005%；即使检验1000次，犯错误的概率还是保持在0.005%×1000 = 5%。最终使得预期犯错误的次数不到1次，抹杀了一切假阳性的概率。
该方法虽然简单，但是检验过于严格，导致最后找不到显著表达的蛋白（假阴性）。&lt;/p&gt;

&lt;p&gt;结合例子🌰说就是：10000人品咖啡应当相应地降低阈值，设成5%/10000=0.0005%（相对应的，增加咖啡杯数，比如让一个人分辨15杯咖啡，这用猜的就很难全对了吧！！！），那么这10000个人只会有5个人能靠猜来答对，大大降低了伪能力者（I类错误）。但是！！！15杯咖啡让真正有辨别能力的小白来喝，也会有味觉疲劳、品错的时候啊。这时候就出现了II类错误（假阴性）——判别小白没有鉴别能力，是靠猜的&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;fdr-比较温和的方法校正p值&#34;&gt;FDR —— “比较温和的方法校正P值”&lt;/h3&gt;

&lt;p&gt;假阳性错误控制法是Benjamini于1995年提出的一种方法。基本原理是通过控制FDR值来决定P值的值域。相对Bonferroni来说，FDR用比较温和的方法对p值进行了校正。其试图在假阳性和假阴性间达到平衡，将假/真阳性比例控制到一定范围之内。例如，如果检验1000次，我们设定的阈值为0.05（5%），那么无论我们进行多少次实验，这些实验结果出现假阳性的概率保持在5%之内，这就叫FDR＜5%。&lt;/p&gt;

&lt;h4 id=&#34;q值&#34;&gt;Q值&lt;/h4&gt;

&lt;p&gt;衡量错误发现率FDR（false discovery rates）的指标。\(FDR=\frac{I型错误数}{总拒绝数} = \frac{V}{R}=Q,R=0时Q=0\)&lt;/p&gt;

&lt;h4 id=&#34;bh法&#34;&gt;BH法&lt;/h4&gt;

&lt;p&gt;那么我们怎么从p value 来估算FDR呢，人们设计了几种不同的估算模型。其中使用最多的是Benjamini and Hochberg方法，简称BH法。虽然这个估算公式并不够完美，但是也能解决大部分的问题，主要还是简单好用！&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;将所有P-value升序排列.P-value记为P，P-value的序号记为i，P-value的总数记为m&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FDR(i)=P(i)*m/i&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;根据i的取值从大到小，依次执行FDR(i)=min{FDR(i),FDR(i+1)}&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注：实际上，BH法的原始算法是找到一个最大的i，满足P≤i/m*FDR阈值，此时，所有小于i的数据就都可以认为是显著的。在实践中，为了能够在比较方便的用不同的FDR阈值对数据进行分析，采用了步骤3里的方法。这个方法可以保证，不论FDR阈值选择多少，都可以直接根据FDR的数值来直接找到所有显著的数据。&lt;/p&gt;

&lt;p&gt;下面我们以一个包含10个数据的例子来看一下FDR计算的过程
&lt;img src=&#34;https://aileenxie.github.io/img/05fdr_80.jpg&#34; alt=&#34;&#34; /&gt;
在这个例子中，第一列是原始的P-value，第二列是排序后的序号，第三列是根据P-value校正得到的初始FDR，第四列是最终用于筛选数据的FDR数值。如果我们设定FDR&amp;lt;0.05，那么绿色高亮的两个数据就是最终分析认为显著的数据。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参考文章&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.plob.org/article/13796.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;差异表达分析之FDR&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zhu_si_tao/article/details/71077703&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;多重假设检验与Bonferroni校正、FDR校正&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>t分布, 卡方x分布，F分布</title>
      <link>https://aileenxie.github.io/2018/04txf/</link>
      <pubDate>Mon, 22 Oct 2018 15:07:13 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/04txf/</guid>
      <description>

&lt;!-- &lt;meta name=&#34;referrer&#34; content=&#34;no-referrer&#34; /&gt; --&gt;

&lt;!-- &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&#34;&gt;&lt;/script&gt; --&gt;

&lt;!-- &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt; --&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;t分布-温良宽厚&#34;&gt;T分布：温良宽厚&lt;/h1&gt;

&lt;p&gt;本文转自“医学统计分析精粹”，小编“Hiu”原创完成，
&lt;a href=&#34;https://www.cnblogs.com/think-and-do/p/6509239.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;原文链接&lt;/a&gt;
&lt;a href=&#34;http://www.cnblogs.com/baiboy/p/tjx11.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;参考文章&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;命名与源起&#34;&gt;命名与源起&lt;/h2&gt;

&lt;p&gt;“t”，是伟大的Fisher为之取的名字。Fisher最早将这一分布命名为“Student&amp;rsquo;s distribution”，并以“t”为之标记。&lt;/p&gt;

&lt;p&gt;Student，则是William Sealy Gosset（戈塞特）的笔名。他当年在爱尔兰都柏林的一家酒厂工作，设计了一种后来被称为t检验的方法来评价酒的质量。因为行业机密，酒厂不允许他的工作内容外泄，所以当他后来将其发表到至今仍十分著名的一本杂志《Biometrika》时，就署了student的笔名。所以现在很多人知道student，知道t，却不知道Gosset。（相对而言，我们常说的正态分布，在国外更多的被称为高斯分布……高斯~泉下有知的话，说不定会打出V字手势~欧耶！）&lt;/p&gt;

&lt;h2 id=&#34;看懂概率密度图&#34;&gt;看懂概率密度图&lt;/h2&gt;

&lt;p&gt;这一点对于初学者尤为重要，相信还是有不少人对正态分布或者t分布的曲线没有确切的理解。&lt;/p&gt;

&lt;p&gt;首先，我们看一下频率分布直方图，histogram：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_33.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图，最关键的就是横轴了，柱高，即，对于横轴上每一个点，发生的频次。图中横轴为4处，次数最多，大约12次；依次类推，横坐标为10处，发生1次……&lt;/p&gt;

&lt;p&gt;我们做单变量的探索性数据分析，最喜欢做柱状图了，或者再额外绘制一条Density曲线于其上（见下图）。很容易就可以看出数据的分布（集中趋势. 离散趋势），图中，数据大多集中在4左右（均数. 众数），有一点点右偏态，但基本还是正态分布。&lt;/p&gt;

&lt;p&gt;下图，手绘曲线，即密度曲线，英文全称&lt;strong&gt;Probability Density Function/Curve&lt;/strong&gt;。实际上是对上面柱状图的一个平滑，但它的纵坐标变为了概率，区别于柱状图的频次。但理解起来意义差不多。
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_40.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以下，我们就用Density曲线来讲解T分布的特征。&lt;/p&gt;

&lt;h3 id=&#34;t分布的可视化&#34;&gt;T分布的可视化&lt;/h3&gt;

&lt;p&gt;我们平常说的t分布，都是指小样本的分布。但其实正态分布，可以算作t分布的特例。也就是说，t分布，在大小样本中都是通用的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;之前有读者问过：“是不是样本量大于30或者大于50，就不能用t分布了呀”？&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;完全不是这样的！t分布，大小通吃！具体且看下文分解&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;相对于正态分布，t分布额外多了一个参数，自由度。自由度  = n - 1。我们先看几个例子，主观感受一下t分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_57.jpg&#34; alt=&#34;&#34; /&gt;
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_58.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可见，随着样本量n / 自由度的增加，t分布越来越接近正态分布。正态分布，可以看做只是t分布的一个特例而已。&lt;/p&gt;

&lt;p&gt;以上部分大家大概都学过的，相信大多数读者都会了解。但这里，让我们回到我们的标题（不是标题党）：&lt;strong&gt;温良宽厚&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;大家仔细比较一下下图。t分布（红色）虽然也是钟型曲线，但是中间较低. 两侧尾巴却很高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_67.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这就是t分布的优势！这个特征相当重要，百年来，t分布就指着这个特征活着的！&lt;/p&gt;

&lt;p&gt;比较一下上图两条曲线，我用这样一个词，“宽厚”，来形容t分布曲线的特征。是不是比正态分布曲线更宽啊？是不是比正态分布曲线更厚呢？&lt;/p&gt;

&lt;p&gt;大家都说重要的事要重复三遍，我们再重复一下，&lt;strong&gt;样本量越小（自由度越小），t分布的尾部越高&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_75.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;尾部的高度-有十分重要的统计学意义&#34;&gt;尾部的高度，有十分重要的统计学意义。&lt;/h3&gt;

&lt;p&gt;我们来比较一下下图中的两条曲线。这两条曲线同样都是对图中底部6个黑色点（数值）进行分布拟合。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;我们首先看一下那条矮的. 正态分布的曲线。我们前面说过，正态分布的曲线不具备“宽厚”的特征。它的尾部很低，尾部与横轴之间高度很“狭窄”。也就是说，正态分布不能够容忍它长长的尾部出现大概率的事件（图中横轴值为15处一圆点出现概率为六分之一），所以正态分布就很无奈地，将这一点纳入它的胸膛而非留在尾部。于是乎，恶果就出现了：图中正态分布的均数，&lt;strong&gt;远远偏离了大多数点所在的位置，标准差也极大&lt;/strong&gt;。总之，与我们所期待的很不一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_86.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;再看一下那条高高的t分布曲线。我们前面说过了，t分布“温良宽厚”，它的尾巴很高（本图中不明显，参见上面自由度为1,2,3时所对应的图片），高高的长尾让它有“容人的雅量”。所以，这条t分布的曲线，很好的捕捉到了数据点的集中趋势（横坐标：0附近）和离散趋势（标准差：只是那条正态分布曲线标准差的四分之一）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这也是T分布盛行的原因，即T分布被广泛应用于&lt;strong&gt;小样本&lt;/strong&gt;假设检验的原因。虽然是很小的样本，但是，却强大到可以&lt;strong&gt;轻松的排除异常值的干扰，准确把握住数据的特征&lt;/strong&gt;（集中趋势和离散趋势）！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;准确捕捉变量的集中趋势和离散趋势在统计中有极为重要的意义，几句话难以说清，简单举几个栗子&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;研究样本量的估计量更小。熟悉样本量计算的朋友也知道，标准差是样本量计算的一个重要参数。上例中，我们t分布的标准差只是正态分布的四分之一，那么我们计算所需的样本量也会极大的减少（只需原来的16分之一），极大地降低研究经费和工作量！（关注“医学统计分析精粹”，回复关键词“样本量”，可以看到很handy的样本量计算工具哦！）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;我们缩小了标准差，熟悉假设检验（将在后续“看图说话”系列文章中出现）的朋友也不难看出，如此，我们更容易得到一个有意义的P值！&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;点估计更准确。如果我们需要根据一个小样本数据来估计学生的平均身高。那么使用正态分布来拟合，很容易就受到离群异常值的影响而得到错误的估计。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;回归中应用t分布，可以得到更稳健的估计量（β值或OR值），这也是我们实现“稳健回归”的一个重要手段。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;通过下面一幅图-我们巩固一下t分布的-宽厚&#34;&gt;通过下面一幅图，我们巩固一下t分布的&lt;strong&gt;“宽厚”&lt;/strong&gt;：&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_110.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;与正态分布曲线（矮胖）比较，t分布以其高高的尾部（本图中不明显，参见上面自由度为1,2,3时所对应的图片），容忍了在横轴为9处的异常值，得到了更稳健的集中趋势估计值（均值1.11）和更紧凑的离散趋势估计值（标准差差0.15，又是正态分布的四分之一）。要知道，我们如果单单想通过增加样本量来将标准误（假设检验中使用的参数，标准差除以自由度的平方根）缩减到四分之一，需要16倍的样本量！可见，t分布当真是威力无穷！&lt;/p&gt;

&lt;p&gt;PS：上述两幅图中的t分布曲线并不是频率学派应用t分布的常规套路（更像是贝叶斯学派的用法）。细心者可以发现，我们使用的t分布的自由度明显低于n - 1的自由度计算方法。这里的自由度是根据最大似然法估计出来的，用以更恰当地拟合数据的分布。虽然这与我们平时的用法不同，但小编觉得，这一点点不同不仅无伤大雅，反而更有利于大家深入理解t分布的特征——温良宽厚。&lt;/p&gt;

&lt;h1 id=&#34;卡方分布的应用&#34;&gt;卡方分布的应用&lt;/h1&gt;

&lt;p&gt;本文来自&lt;a href=&#34;http://www.cnblogs.com/baiboy/p/tjx11.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://www.cnblogs.com/baiboy/p/tjx11.html&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;提到统计学，很多人认为是经济学或者数学的专利，与计算机并没有交集。诚然在传统学科中，其在以上学科发挥作用很大。然而随着科学技术的发展和机器智能的普及，统计学在机器智能中的作用越来越重要。本系列统计学学习基于李航的《统计学习方法》一书和一些基本的概率知识。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;统计和数学模型对机器智能发挥重大的作用。诸如：语音识别. 词性分析. 机器翻译等世界级的难题也是从统计中找到开启成功之门钥匙的。尤其是在自然语言处理方面更显得重要。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;目录&lt;/p&gt;

&lt;p&gt;1 题引和基本知识介绍&lt;/p&gt;

&lt;p&gt;2 卡方检验拟合优度（问题一）&lt;/p&gt;

&lt;p&gt;3 卡方检验两个变量的独立性（问题二）&lt;/p&gt;

&lt;p&gt;4 本章小结&lt;/p&gt;

&lt;p&gt;5 内容扩展&lt;/p&gt;

&lt;h2 id=&#34;1-题引和基本知识介绍&#34;&gt;1 题引和基本知识介绍&lt;/h2&gt;

&lt;h3 id=&#34;1-什么是卡方分布&#34;&gt;1 什么是卡方分布?&lt;/h3&gt;

&lt;p&gt;  若n个相互独立的随机变量ξ₁. ξ₂. ……. ξn ，均服从标准正态分布（也称独立同分布于标准正态分布），则这n个服从标准正态分布的随机变量的平方和&lt;/p&gt;

&lt;p&gt;$$Q= \sum_{i=1}^{n}\xi _{i}^{2}$$&lt;/p&gt;

&lt;p&gt;构成一新的随机变量，其卡方分布规律称为&lt;strong&gt;\(\chi ^{2}\)分布（chi-square distribution）&lt;/strong&gt;，其中参数&lt;strong&gt;n称为自由度&lt;/strong&gt;，正如正态分布中均值或方差不同就是另一个\(\chi ^{2}\)正态分布一样，自由度不同就是另一个分布。记为 Q ~ \(\chi ^{2}(k)\). 卡方分布是由正态分布构造而成的一个新的分布，当自由度n很大时，\(\chi ^{2}\)分布近似为正态分布。 对于任意正整数k， 自由度为 k的卡方分布是一个随机变量X的机率分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_150.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-为什么要引用卡方分布&#34;&gt;2 为什么要引用卡方分布?&lt;/h3&gt;

&lt;p&gt;  以特定概率分布为某种情况建模时，事物长期结果较为稳定，能够清晰进行把握。但是期望与事实存在差异怎么办？偏差是正常的小幅度波动？还是建模错误？此时，利用卡方分布分析结果，排除可疑结果。【事实与期望不符合情况下使用卡方分布进行检验】&lt;/p&gt;

&lt;h3 id=&#34;3-生活中又怎样的事例-抽奖机之谜-会出现这种现象呢&#34;&gt;3 生活中又怎样的事例（抽奖机之谜）会出现这种现象呢？&lt;/h3&gt;

&lt;p&gt;  抽奖机，肯定都不陌生，现在一些商场超市门口都有放置。正常情况下出奖概率是一定的，基本商家收益。倘若突然某段时间内总是出奖，甚是反常，那么到底是某阶段是小概率事件还是有人进行操作了？抽奖机怎么了？针对这种现象或者类似这种现象问题则可以借助卡方进行检验，暂且不着急如何检验，还是补充一下基础知识，再逐步深入解决问题。【常规事件中出现非常规现象，如何检查问题所在的情况下使用卡方分布】&lt;/p&gt;

&lt;h3 id=&#34;4-问题描述-抽奖机之谜&#34;&gt;4 问题描述：抽奖机之谜？&lt;/h3&gt;

&lt;h4 id=&#34;问题一-卡方检验拟合优度案例&#34;&gt;问题一：卡方检验拟合优度案例&lt;/h4&gt;

&lt;p&gt;下面是某台抽奖机的期望分布，其中X代表每局游戏的净收益（每局独立事件）：
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_162.jpg&#34; alt=&#34;&#34; /&gt;
实际中人们收益的频数为：
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_164.jpg&#34; alt=&#34;&#34; /&gt;
在5%的显著性水平下，看看能否有足够证据证明判定抽奖机被人动了手脚。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;解题思路：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;算出每个x值的实际频率与根据概率分布得出的期望频率进行比较？&lt;/li&gt;
&lt;li&gt;利用抽奖机的观察频率和期望频率表计算检验统计量？&lt;/li&gt;
&lt;li&gt;要检验的原假设是什么？备择假设是什么？&lt;/li&gt;
&lt;li&gt;自由度为4且5%水平的拒绝域是多少？&lt;/li&gt;
&lt;li&gt;检验统计量是多少？&lt;/li&gt;
&lt;li&gt;检验统计量是在拒绝域以内还是拒绝域以外？&lt;/li&gt;
&lt;li&gt;你将接受还是拒绝原假设？&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;问题二-卡方检验独立性案例&#34;&gt;问题二：卡方检验独立性案例&lt;/h4&gt;

&lt;p&gt;下表显示各位庄家的观察频数，
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_179.jpg&#34; alt=&#34;&#34; /&gt;
以1%的显著性水平进行假设检验，看看赌局结果是否独立于坐庄庄家。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;解题思路：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;你是任务是算出所有期望频数。&lt;/li&gt;
&lt;li&gt;根据上面所求期望频数，计算检验统计量\(X ^{2}\).&lt;/li&gt;
&lt;li&gt;确定要进行检验的假设以及备择假设。&lt;/li&gt;
&lt;li&gt;求出期望频率和自由度？&lt;/li&gt;
&lt;li&gt;确定用于做决策的拒绝域。&lt;/li&gt;
&lt;li&gt;计算检验统计量\(X ^{2}\)&lt;/li&gt;
&lt;li&gt;看看检验统计量是否位于拒绝域内。&lt;/li&gt;
&lt;li&gt;作出决策。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-卡方检验拟合优度-问题一&#34;&gt;2 卡方检验拟合优度（问题一）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;问题简述:&lt;/p&gt;

&lt;p&gt;抽奖机平常收益者总是商家，突然一段时间总是出奖。本来小概率事件频发，我们利用卡方的检验拟合优度看看能否有足够证据证明判定抽奖机被人动了手脚&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-知识储备-期望频数计算&#34;&gt;1 知识储备：期望频数计算&lt;/h3&gt;

&lt;p&gt;期望频数=（观察频数之和（1000）） X （每种结果的概率） 如：X=(-2)的期望频数：977=（0.977）X（1000）
利用卡方假设检验观察频数和期望频数之间的差别。&lt;/p&gt;

&lt;h4 id=&#34;1-算出每个x值的实际频率与根据概率分布得出的期望频率进行比较&#34;&gt;1. 算出每个x值的实际频率与根据概率分布得出的期望频率进行比较？&lt;/h4&gt;

&lt;p&gt;解答：
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_205.jpg&#34; alt=&#34;&#34; /&gt;   &lt;/p&gt;

&lt;h3 id=&#34;2-知识储备-卡方检验评估差异&#34;&gt;2 知识储备：卡方检验评估差异&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卡方分布&lt;/strong&gt;：通过一个检验统计量来比较期望结果和实际结果之间的差别，然后得出观察频数极值的发生概率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算统计量步骤&lt;/strong&gt;： （期望频数总和与观察频数总和相等）

&lt;ol&gt;
&lt;li&gt;表里填写相应的观察频数和期望频数&lt;/li&gt;
&lt;li&gt;利用卡方公式计算检验统计量：（O代表观察期望，E代表期望频数）
$$\chi ^{2}=\sum \frac{(O-E)^{2}}{E}$$
注释： 其中\(\chi ^{2}\)表示检验统计量，O表示观察频数，E代表期望频数。
即：对于概率分布的每一个概率，取期望频数和实际频数的差，求差的平方数，再除以期望频数，然后将所有结果相加。
检验统计量意义：O与E之间差值越小，检验统计量越小。以E为除数，令差值与期望频数成比例。
卡方检验的标准：如果统计量值\(\chi ^{2}\)很小，说明观察频数和期望频数之间的差别不显著，统计量越大，差别越显著。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;2-利用抽奖机的观察频率和期望频率表计算检验统计量&#34;&gt;2. 利用抽奖机的观察频率和期望频率表计算检验统计量？&lt;/h4&gt;

&lt;p&gt;解答：
    &lt;img src=&#34;https://aileenxie.github.io/img/04txf_221.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-知识储备-卡方假设检验&#34;&gt;3 知识储备：卡方假设检验&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卡方分布的用途&lt;/strong&gt;：检查实际结果与期望结果之间何时存在显著差异。&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;检验拟合优度：也就是说可以检验一组给定数据与指定分布的吻合程度。如：用它检验抽奖机收益的观察频数与我们所期望的吻合程度。&lt;/li&gt;
&lt;li&gt;检验两个变量的独立性：通过这个方法检查变量之间是否存在某种关系。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;自由度V:&lt;/strong&gt; 用于计算检验统计量的独立变量的数目。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;自由度希腊字母V，读作“纽”，v影响概率分布&lt;/li&gt;
&lt;li&gt;当v等于1或者2时：卡方分布先高后低的平滑曲线，检验统计量等于较小值的概率远远大于较大值的概率，即观察频数有可能接近期望频数。图形：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_233.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;当v大于2时：卡方分布先低后高再低，其外形沿着正向扭曲，但当v很大时，图形接近正态分布。图形：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_235.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;特定参数v（缪）的卡方分布以及检验统计量可以记作：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_237.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;v的计算： (如例子：v=5-1)
     $$v=(组数) - (限制数)$$&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;显著性:&lt;/strong&gt; 卡方分布指出观察频数与期望频数之间差异显著性，和其他假设一样，这取决于显著性水平。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;显性水平α进行检验，则写作：（&lt;strong&gt;常用的显著性水平1%和5%&lt;/strong&gt;）
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_244.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;检测标准：卡方分布检验是单尾检验且是右尾，右尾被作为拒绝域。于是通过查看检验统计量是否位于右尾的拒绝域以内，来判定期望分布得出结果的可能性。
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_246.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;卡方概率表的使用：卡方临界值表是给定可以查询的
例如： 5%的显著性水平，8的自由度进行检验。查出15.51，因此只要检验统计量大于15.51，检验统计量就位于拒绝域内。  
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_249.jpg&#34; alt=&#34;&#34; /&gt;  
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卡方分布假设检验:&lt;/strong&gt; （总是使用右尾）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;确定要进行检验的假设（H0）及其备择假设H1.&lt;/li&gt;
&lt;li&gt;求出期望E和自由度V.&lt;/li&gt;
&lt;li&gt;确定用于做决策的拒绝域（右尾）.&lt;/li&gt;
&lt;li&gt;计算检验统计量.&lt;/li&gt;
&lt;li&gt;查看检验统计量是否在拒绝域内.&lt;/li&gt;
&lt;li&gt;做出决策.
卡方分布检验其实就是假设检验的特殊形式。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;3-要检验的原假设是什么-备择假设是什么&#34;&gt;3. 要检验的原假设是什么？备择假设是什么？&lt;/h4&gt;

&lt;p&gt;解答：
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_266.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-知识储备-拒绝域求解&#34;&gt;4 知识储备：拒绝域求解&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_270.jpg&#34; alt=&#34;&#34; /&gt;
例如： 5%的显著性水平，8的自由度进行检验。查出15.51，因此只要检验统计量大于15.51，检验统计量就位于拒绝域内。         &lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;4-自由度为4-5-水平的拒绝域是多少&#34;&gt;4. 自由度为4,5%水平的拒绝域是多少？&lt;/h4&gt;

&lt;p&gt;解答：
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_275.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-知识储备-计算检验统计量&#34;&gt;5 知识储备:计算检验统计量&lt;/h3&gt;

&lt;p&gt;前面已经求过。&lt;/p&gt;

&lt;h4 id=&#34;5-检验统计量是多少&#34;&gt;5. 检验统计量是多少？&lt;/h4&gt;

&lt;p&gt;解答：
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_282.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;6-知识储备-检验统计量拒绝域内外判定&#34;&gt;6 知识储备：检验统计量拒绝域内外判定&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;求出检验统计量a&lt;/li&gt;
&lt;li&gt;通过自由度和显著性水平查到拒绝域临界值b&lt;/li&gt;
&lt;li&gt;a&amp;gt;b则位于拒绝域内，反之，位于拒绝域外。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;6-检验统计量是在拒绝域以内还是拒绝域以外&#34;&gt;6. 检验统计量是在拒绝域以内还是拒绝域以外？&lt;/h4&gt;

&lt;p&gt;解答：
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_292.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;7-知识储备-决策原则&#34;&gt;7 知识储备：决策原则&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;如果位于拒绝域内我们拒绝原假设H0，接受H1。
如果不在拒绝域内我们接受原假设H0，拒绝H1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;7-你将接受还是拒绝原假设&#34;&gt;7. 你将接受还是拒绝原假设？&lt;/h4&gt;

&lt;p&gt;解答：
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_301.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注：只有能得到一组观察频数且算出期望频数，卡方可以检验任何概率分布的拟合优度。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;揭晓谜底：抽奖机被人动了手脚！！！！！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-卡方检验两个变量的独立性-问题二&#34;&gt;3 卡方检验两个变量的独立性（问题二）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;【问题简述】:
抽奖机被人动过手脚，经过技术人员处理得以解决，但是现在新问题出现了，因为老板发现负责二十一点赌桌的庄家佩服的钱高于合理值。怀疑庄家是内鬼。究竟赌局结果是否取决于坐庄的庄家，即庄家是否暗箱操作，赌局结果与庄家是否有关？此问题需要卡方分布检查独立性破案。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;【问题二】下表显示各位庄家的观察频数，
     &lt;img src=&#34;https://aileenxie.github.io/img/04txf_313.jpg&#34; alt=&#34;&#34; /&gt;
以1%的显著性水平进行假设检验，看看赌局结果是否独立于坐庄庄家。&lt;/p&gt;

&lt;h3 id=&#34;1-知识储备-利用概率求期望频数&#34;&gt;1 知识储备：利用概率求期望频数&lt;/h3&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;独立性检验：用于判断两种因素是否相互独立，或者两者是否有联系。&lt;/li&gt;
&lt;li&gt;期望概率求解步骤：

&lt;ol&gt;
&lt;li&gt;算出赌局结果和庄家频数以及各项总和，如下表称为列联表
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_321.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;算出庄家A的赢局期望。

&lt;ol&gt;
&lt;li&gt;求出赢局概率：P(赢)=赢局合计/总和&lt;/li&gt;
&lt;li&gt;庄家A坐庄概率：P(A)=合计A/总和&lt;/li&gt;
&lt;li&gt;假设庄家A和赌局结果独立，其坐庄出现赢局概率：P(A坐庄赢局)=P(赢) X P(A)&lt;/li&gt;
&lt;li&gt;赢局的期望频数=总和*P(A坐庄赢局) 即： &lt;img src=&#34;https://aileenxie.github.io/img/04txf_326.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;推广：期望频数= 行合计 X 列合计 / 总和&lt;/li&gt;
&lt;li&gt;求出检验统计量：（与前面一样）
$$\chi ^{2}=\sum \frac{(O-E)^{2}}{E}$$&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;1-你是任务是算出所有期望频数&#34;&gt;1. 你是任务是算出所有期望频数。&lt;/h4&gt;

&lt;p&gt;解答：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_334.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-根据上面所求期望频数-计算检验统计量x-2&#34;&gt;2. 根据上面所求期望频数，计算检验统计量X^2.&lt;/h4&gt;

&lt;p&gt;解答：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_338.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-确定要进行检验的假设以及备择假设&#34;&gt;3. 确定要进行检验的假设以及备择假设。&lt;/h4&gt;

&lt;p&gt;解答：
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_342.jpg&#34; alt=&#34;&#34; /&gt; &lt;/p&gt;

&lt;h4 id=&#34;4-求出期望频率和自由度&#34;&gt;4. 求出期望频率和自由度？&lt;/h4&gt;

&lt;p&gt;解答：
   &lt;img src=&#34;https://aileenxie.github.io/img/04txf_346.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-确定用于做决策的拒绝域&#34;&gt;5. 确定用于做决策的拒绝域。&lt;/h4&gt;

&lt;p&gt;解答：
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_350.jpg&#34; alt=&#34;&#34; /&gt; &lt;/p&gt;

&lt;h4 id=&#34;6-计算检验统计量x-2&#34;&gt;6. 计算检验统计量X^2&lt;/h4&gt;

&lt;p&gt;解答：
   &lt;img src=&#34;https://aileenxie.github.io/img/04txf_354.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;7-看看检验统计量是否位于拒绝域内&#34;&gt;7. 看看检验统计量是否位于拒绝域内。&lt;/h4&gt;

&lt;p&gt;解答：
   &lt;img src=&#34;https://aileenxie.github.io/img/04txf_358.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;8-作出决策&#34;&gt;8. 作出决策。&lt;/h4&gt;

&lt;p&gt;解答：
   &lt;img src=&#34;https://aileenxie.github.io/img/04txf_362.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-自由度计算方法归纳&#34;&gt;2 自由度计算方法归纳：&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;列联表自由度计算，表如下k列，h行
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_366.jpg&#34; alt=&#34;&#34; /&gt;
$$v=(h-1) X (k-1)$$
 注释：每行计算到最后一个，可直接用（总数 - 本行其他值），故同一行中限制数只有一个，列同理。故如上式。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;注：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;在拟合优度检验中，v=组数 - 限制数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在两个变量独立性检验中，如列联表为h行k列则：v=(h-1) X (k-1)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;4-本章小结&#34;&gt;4 本章小结&lt;/h2&gt;

&lt;h3 id=&#34;1-为什么要引用卡方分布&#34;&gt;1 为什么要引用卡方分布?&lt;/h3&gt;

&lt;p&gt;  以特定概率分布为某种情况建模时，事物长期结果较为稳定，能够清晰进行把握。但是期望与事实存在差异怎么办？偏差是正常小幅度波动或是在建模错误如何判别？此时，利用卡方分布分析结果，排除可疑结果。&lt;strong&gt;【事实与期望不符合情况下使用卡方分布进行检验】&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-卡方检验拟合优度案例&#34;&gt;2 卡方检验拟合优度案例&lt;/h3&gt;

&lt;h4 id=&#34;期望计算&#34;&gt;+ 期望计算：&lt;/h4&gt;

&lt;p&gt;期望频数=（观察频数之和（1000）） X （每种结果的概率） 如：-2：977=（0.977）X（1000）&lt;/p&gt;

&lt;h4 id=&#34;卡方分布&#34;&gt;+ 卡方分布&lt;/h4&gt;

&lt;p&gt;通过一个检验统计量来比较期望结果和实际结果之间的差别，然后得出观察频数极值的发生概率。&lt;/p&gt;

&lt;h4 id=&#34;计算统计量步骤-期望频数总和与观察频数总和相等&#34;&gt;+ 计算统计量步骤：（期望频数总和与观察频数总和相等）&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;表里填写相应的观察频数和期望频数&lt;/li&gt;
&lt;li&gt;利用卡方公式计算检验统计量：（O代表观察期望，E代表期望频数）
$$\chi ^{2}=\sum \frac{(O-E)^{2}}{E}$$
即：对于概率分布的每一个概率，取期望频数和实际频数的差，求差的平方数，再除以期望频数，然后将所有结果相加。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;检验统计量意义&#34;&gt;+ 检验统计量意义&lt;/h4&gt;

&lt;p&gt;  O与E之间差值越小，检验统计量越小。以E为除数，令差值与期望频数成比例。 卡方检验的标准：如果统计量值（X^2）很小，说明观察频数和期望频数之间的差别不显著，统计量越大，差别越显著。&lt;/p&gt;

&lt;h4 id=&#34;卡方分布的用途&#34;&gt;+ 卡方分布的用途&lt;/h4&gt;

&lt;p&gt;检查实际结果与期望结果之间何时存在显著差异。
1. 检验拟合优度：也就是说可以检验一组给定数据与指定分布的吻合程度。如：用它检验抽奖机收益的观察频数与我们所期望的吻合程度。    
2. 检验两个变量的独立性：通过这个方法检查变量之间是否存在某种关系。&lt;/p&gt;

&lt;h4 id=&#34;自由度v&#34;&gt;+ 自由度V&lt;/h4&gt;

&lt;p&gt;用于计算检验统计量的独立变量的数目。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;自由度希腊字母V，读作“纽”，v影响概率分布&lt;/li&gt;
&lt;li&gt;当v等于1或者2时：卡方分布先高后低的平滑曲线，检验统计量等于较小值的概率远远大于较大值的概率，即观察频数有可能接近期望频数。      3. 当v大于2时：卡方分布先低后高再低，其外形沿着正向扭曲，但当v很大时，图形接近正态分布。&lt;/li&gt;
&lt;li&gt;特定参数v（缪）的卡方分布以及检验统计量&lt;/li&gt;
&lt;li&gt;v的计算： (如例子：v=5-1)
        v=(组数) - (限制数)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;显著性&#34;&gt;+ 显著性&lt;/h4&gt;

&lt;p&gt;卡方分布指出观察频数与期望频数之间差异显著性，和其他假设一样，这取决于显著性水平。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;显性水平α进行检验，则写作：（常用的显著性水平1%和5%）&lt;/li&gt;
&lt;li&gt;检测标准：卡方分布检验是单尾检验且是右尾，右尾被作为拒绝域。于是通过查看检验统计量是否位于右尾的拒绝域以内，来判定期望分布得出结果的可能性。&lt;/li&gt;
&lt;li&gt;卡方概率表的使用：卡方临界值表是给定可以查询的&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;卡方分布假设检验步骤-总是使用右尾&#34;&gt;+ 卡方分布假设检验步骤： 总是使用右尾&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;确定要进行检验的假设（H0）及其备择假设H1.&lt;/li&gt;
&lt;li&gt;求出期望E和自由度V.&lt;/li&gt;
&lt;li&gt;确定用于做决策的拒绝域（右尾）.&lt;/li&gt;
&lt;li&gt;计算检验统计量.&lt;/li&gt;
&lt;li&gt;查看检验统计量是否在拒绝域内.&lt;/li&gt;
&lt;li&gt;做出决策.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;卡方分布检验其实就是假设检验的特殊形式。&lt;/p&gt;

&lt;h4 id=&#34;决策原则&#34;&gt;+ 决策原则&lt;/h4&gt;

&lt;p&gt;如果位于拒绝域内我们拒绝原假设H0，接受H1。 如果不在拒绝域内我们接受原假设H0，拒绝H1&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;卡方检验两个变量的独立性（问题二）&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;独立性检验&#34;&gt;+ 独立性检验：&lt;/h4&gt;

&lt;p&gt;用于判断两种因素是否相互独立，或者两者是否有联系。&lt;/p&gt;

&lt;h4 id=&#34;期望概率求解步骤&#34;&gt;+ 期望概率求解步骤：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;算出赌局结果和庄家频数以及各项总和，如下表称为列联表&lt;/li&gt;
&lt;li&gt;算出庄家A的赢局期望。

&lt;ol&gt;
&lt;li&gt;求出赢局概率：P(赢)=赢局合计/总和&lt;/li&gt;
&lt;li&gt;庄家A坐庄概率：P(A)=合计A/总和&lt;/li&gt;
&lt;li&gt;假设庄家A和赌局结果独立，其坐庄出现赢局概率：P(A坐庄赢局)=P(赢) X P(A)&lt;/li&gt;
&lt;li&gt;赢局的期望频数=总和*P(A坐庄赢局)
即：&lt;img src=&#34;https://aileenxie.github.io/img/04txf_452.jpg&#34; alt=&#34;&#34; /&gt;
    &lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;推广&#34;&gt;+ 推广：&lt;/h4&gt;

&lt;p&gt;$$期望频数= (行合计 X 列合计) / 总和$$&lt;/p&gt;

&lt;h4 id=&#34;求出检验统计量-与前面一样&#34;&gt;+ 求出检验统计量：（与前面一样）&lt;/h4&gt;

&lt;p&gt;$$\chi ^{2}=\sum \frac{(O-E)^{2}}{E}$$&lt;/p&gt;

&lt;h4 id=&#34;自由度计算方法归纳&#34;&gt;+ 自由度计算方法归纳：&lt;/h4&gt;

&lt;p&gt;  列联表自由度计算，表如下k列，h行
  &lt;img src=&#34;https://aileenxie.github.io/img/04txf_466.jpg&#34; alt=&#34;&#34; /&gt;        
$$v=(h-1) X (k-1)$$
注释：每行计算到最后一个，用总数-其他之后，故一个数限制，同列一列限制。故如上式。&lt;/p&gt;

&lt;p&gt;注：
1. 在拟合优度检验中，v=组数 - 限制数
2. 在两个变量独立性检验中，如列联表为h行k列则：v=(h-1) X (k-1)&lt;/p&gt;

&lt;h1 id=&#34;f-分布&#34;&gt;F 分布&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_478.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;研究A. B. C三种不同学校学生的阅读理解成绩找到一种解决的办法，有人可能会以为，只要多次使用Z检验或t检验，比较成对比较学校（或条件）即可。但是我们不会这样来处理。因为Z检验或t检验有其&lt;strong&gt;局限性&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;比较的组合次数增多，上例需要3次，如果研究10个学校，需要45个&lt;/li&gt;
&lt;li&gt;降低可靠程度，如果我们做两次检验，每次都为0.05的显著性水平，那么不犯Ⅰ型错误的概率就变为0.95×0.95＝0.90。此时犯Ⅰ型错误的概率则为1-0.90＝0.10，即至少犯一次Ⅰ型错误的概率翻了一倍。若做10次检验的话，至少犯一次Ⅰ型错误的概率将上升到0.40（1-0.952），而10次检验结论中都正确的概率只有60%。所以说采用Z检验或t检验随着均数个数的增加，其组合次数增多，从而降低了统计推论可靠性的概率，增大了犯错误的概率&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;完全随机设计是采用完全随机化的分组方法，将全部实验对象分配到g个处理组（水平组），各组分别接受不同的处理，试验结束后比较各组均数之间的差别有无统计学意义。&lt;/p&gt;

&lt;p&gt;【例子】&lt;/p&gt;

&lt;p&gt;某医生为研究一种四类降糖新药的疗效，以统一的纳入标准和排除标准选择了60名2型糖尿病患者，按完全随机设计方案将患者分为三组进行双盲临床试验。其中，降糖新药高剂量组21人. 低剂量组19人. 对照组20人。对照组服用公认的降糖药物，治疗4周后测得其餐后2小时血糖的下降值(mmol/L)，结果如表9-1所示。问治疗4周后，餐后2小时血糖下降值的三组总体平均水平是否不同？
 &lt;img src=&#34;https://aileenxie.github.io/img/04txf_494.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;总平均数：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_497.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;各处理组平均数：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_500.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;总例数：
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_504.jpg&#34; alt=&#34;&#34; /&gt;
g为处理组数&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;定义&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;总变异：全部测量值各不相同，这种变异称为总变异。总变异的大小可以用均差平方和SS来表示，即各测量值Xij与总平均数差值的平方和，SS总，反映那个了所有测量值之间总的变异程度。&lt;img src=&#34;https://aileenxie.github.io/img/04txf_510.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;组内变异（误差变异）：同一处理组中的受试对象接受相同的处理，其测量值间各不相同。这种变异称为组内变异。SS组内 组内各测量值Xij与其所在组的均数的差值的平方和，表示随机误差的影响。&lt;img src=&#34;https://aileenxie.github.io/img/04txf_511.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;组间变异，各处理组接受处理的水平不同，各组的样本均数各不相同，这种变异称为组间变异。其大小可以用各组均数与总均数的离均差平方和SS组间，反应了三组用药不同的影响（如果处理确实有作用），同时也包括了随机误差。&lt;img src=&#34;https://aileenxie.github.io/img/04txf_512.jpg&#34; alt=&#34;&#34; /&gt;
存在组间变异的原因：
（1）随机误差
（2）不同处理水平可能对实验结果的影响&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;方差分析的基本思想：&lt;/strong&gt;总变异分解为多个部分，每个部分由某因素的作用来解释，通过将某因素所致的变异与随机误差比较，从而推断该因素对测定结果有无影响。变异程度除与离均差平方和的大小有关外，还与自由度有关，将各部分离均差平方和除以自由度，比值称为均方差MS：&lt;img src=&#34;https://aileenxie.github.io/img/04txf_517.jpg&#34; alt=&#34;&#34; /&gt;
如果各组样本来自&lt;strong&gt;相同总体&lt;/strong&gt;，无处理因素的作用，则组间变异同组内变异一样，&lt;strong&gt;只反应随机误差作用的大小&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;组间均方与组内均方的比值称为&lt;strong&gt;F统计量&lt;/strong&gt;：&lt;img src=&#34;https://aileenxie.github.io/img/04txf_519.jpg&#34; alt=&#34;&#34; /&gt;
F值接近于1，就没有理由拒绝H0（来自相同总体），反之，F值越大，拒绝H0的理由越充分。当H0成立时，F统计量服从F分布，自由度v1和v2，Fv1,v2&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/04txf_522.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://aileenxie.github.io/img/04txf_523.jpg&#34; alt=&#34;&#34; /&gt;
v1=组间自由度 = g-1 = 3-1 v2=组内自由度=N-g= 60-3 = 57，查F分布表得到P&amp;lt;0.01，按α=0.05水准，拒绝H0，接受H1有统计学意义，可认为2型糖尿病患者治疗4周，其餐后2小时血糖的总体平均水平不全相同。&lt;/p&gt;

&lt;p&gt;方差分析的结果若拒绝H0，接受H1，不能说明各组总体均数两两间都有差别。如果要分析哪些两组间有差别，要进行多个均数间的多重比较（&lt;strong&gt;卡方检验&lt;/strong&gt;）。当g =2时，方差分析的结果与两样本均数比较的t 检验等价 t=sqrt(F)。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>近端梯度（Proximal Gradient, PG）算法详解</title>
      <link>https://aileenxie.github.io/2018/03pg/</link>
      <pubDate>Fri, 19 Oct 2018 15:07:13 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/03pg/</guid>
      <description>

&lt;!-- &lt;meta name=&#34;referrer&#34; content=&#34;no-referrer&#34; /&gt; --&gt;

&lt;!-- &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&#34;&gt;&lt;/script&gt; --&gt;

&lt;!-- &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt; --&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=default&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;pg算法&#34;&gt;PG算法&lt;/h1&gt;

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;Proximal算法是用于求解凸优化问题的方法之一。用于求解目标函数形如f(x)=g(x)+h(x)（其中g(x)可微而h(x)不可微）形式无约束问题的下降算法。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当无约束的凸优化问题可微，我们可以用梯度下降算法求解；&lt;/li&gt;
&lt;li&gt;当无约束的凸优化目标函数不可微，我们可以采用次梯度(subgradient)算法求解(该算法时间复杂度较高,且不会产生稀疏)；&lt;/li&gt;
&lt;li&gt;当存在约束时，我们可以采用proximal相关梯度算法求解(可降低复杂度至O(1/ϵ));&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这是因为，当目标函数存在约束时，我们可以把约束写入目标函数，但是这时候往往目标函数就从可微变成不可微，例如线性回归加入L−1norm，记为\( ∥y−xβ∥_2^2+λ∥β∥_1\) ，那么很明显，目标函数前半部分为凸且连续可微，但后半部分为凸但不连续可微。&lt;/p&gt;

&lt;h2 id=&#34;算法模型&#34;&gt;算法模型&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_24.jpg&#34;width=&#34;30%&#34; height=&#34;30%&#34;&gt;
其中g(x)为&lt;a href=&#34;https://blog.csdn.net/feilong_csdn/article/details/83476277&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;凸函数&lt;/a&gt;，可微。h(x)也是凸函数，但不可微。其中g(x),h(x)是由F(x) 分离出来的两项，当F(x) 分离的结果不同，即使是同一个问题，算法的实现方式也不尽相同，&lt;/p&gt;

&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;

&lt;h3 id=&#34;临近算子-proximity-operator&#34;&gt;【临近算子】（proximity operator）&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_29.jpg&#34;width=&#34;50%&#34; height=&#34;50%&#34;&gt;&lt;/p&gt;

&lt;h4 id=&#34;当h-x-0-则prox-h-x-arg-min-u-frac-1-2-u-x-2-2-x&#34;&gt;&amp;gt; 当h(x)=0,则prox\(h\)(x)=\(arg \min _{u}\)(\(\frac{1}{2}||u−x||_2^2\))=x;&lt;/h4&gt;

&lt;h4 id=&#34;当h-x-ic-则prox-h-x-arg-min-u-c-frac-1-2-u-x-2-2-pc-x&#34;&gt;&amp;gt; 当h(x)=Ic，则prox\(h\)(x)=\(arg \min _{u∈c}\)(\(\frac{1}{2}||u−x||_2^2\))=Pc(x);&lt;/h4&gt;

&lt;h4 id=&#34;当h-x-t-x-1-则prox-h-x-为-软阈值-https-blog-csdn-net-jbb0523-article-details-52103257-算法&#34;&gt;&amp;gt; 当h(x)=\(t||X||_1\)，则prox\(h(x)\) 为&lt;a href=&#34;https://blog.csdn.net/jbb0523/article/details/52103257&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;软阈值&lt;/a&gt;算法。&lt;/h4&gt;

&lt;p&gt;临近算子是对梯度的延伸，只与h(x)有关，当函数h(x)为光滑函数时，该临近算子就是梯度。&lt;/p&gt;

&lt;h3 id=&#34;f-x-的-近端梯度-proximal-gradient&#34;&gt;F(x)的【近端梯度】（proximal gradient）&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_40.jpg&#34; width=&#34;40%&#34; height=&#34;40%&#34;&gt;
近端梯度就是对F(x)梯度的近似，其中：
&lt;img src=&#34;https://aileenxie.github.io/img/03pg_42.jpg&#34; width=&#34;50%&#34; height=&#34;50%&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;集合x的-指示函数-indicator-function&#34;&gt;集合X的【指示函数】（indicator function）&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_45.jpg&#34; width=&#34;30%&#34; height=&#34;30%&#34;&gt;&lt;/p&gt;

&lt;p&gt;其中X是一个凸集合。利用指示函数，我们可以将有约束问题写成无约束问题,如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_49.jpg&#34; width=&#34;40%&#34; height=&#34;40%&#34;&gt;&lt;/p&gt;

&lt;p&gt;当x不在X中，等式为无穷大，因此x肯定不是最优值。因此就等于限定了x在凸集合X中。&lt;/p&gt;

&lt;h3 id=&#34;变量x在集合x上的-投影算子-projection-operator&#34;&gt;变量x在集合X上的【投影算子】（projection operator）&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_54.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;投影的含义：一个点x在集合X上的投影，就是X上离x的欧几里得距离最近的点。&lt;/p&gt;

&lt;p&gt;Tips:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2个在集合外的点x，y之间的距离，一定大于这两点在凸集合X上的投影的距离&lt;/li&gt;
&lt;li&gt;当h(x)=\(l_{X}(x)\)时，\(proj_x(x)=prox_h(x)\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;算法实现&#34;&gt;算法实现&lt;/h2&gt;

&lt;p&gt;迭代计算最优解x，直到F(x)在最小值附近收敛。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://aileenxie.github.io/img/03pg_67.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;算法伪代码：
&lt;img src=&#34;https://aileenxie.github.io/img/03pg_70.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Proximal Algorithms&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://freemind.pluskid.org/machine-learning/projected-gradient-method-and-lasso/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Projected Gradient Method and LASSO
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/lanyanchenxi/article/details/50448640&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;CSDN-Proximal Gradient Method近端梯度算法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq547276542/article/details/78251779&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;近端梯度法(Proximal Gradient Method, PG)&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>L0,L1,L2以及核范数规则化</title>
      <link>https://aileenxie.github.io/2018/02l_norm/</link>
      <pubDate>Wed, 10 Oct 2018 19:17:39 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/02l_norm/</guid>
      <description>

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&#34;&gt;&lt;/script&gt;

&lt;p&gt;看到一篇讲解很详细的&lt;a href=&#34;https://blog.csdn.net/zouxy09/article/details/24971995&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;文章&lt;/a&gt;，边看边做笔记整理要点。
先放一张范数汇总图：
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_14.jpg&#34;width=&#34;100%&#34; height=&#34;100%&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;监督机器学习问题无非就是“minimizeyour error while regularizing your parameters”，也就是在规则化参数的同时最小化误差。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最小化误差&lt;/strong&gt;是为了让我们的模型拟合我们的训练数据，而&lt;strong&gt;规则化参数&lt;/strong&gt;是防止我们的模型过分拟合我们的训练数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过拟合：参数过多会导致模型复杂度上升，产生过拟合，即训练误差很小，但测试误差很大，这和监督学习的目标是相违背的。所以需要采取措施，保证模型尽量简单的基础上，最小化训练误差，使模型具有更好的泛化能力。&lt;/li&gt;
&lt;li&gt;泛化能力强：测试误差也很小&lt;/li&gt;

&lt;li&gt;&lt;p&gt;范数规则化有两个作用：&lt;/p&gt;

&lt;p&gt;1）保证模型尽可能的简单，避免过拟合。&lt;/p&gt;

&lt;p&gt;2）约束模型特性，加入一些先验知识，例如稀疏、低秩等。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;目标函数&#34;&gt;目标函数&lt;/h2&gt;

&lt;p&gt;一般来说，监督学习可以看做最小化下面的目标函数：
&lt;img src=&#34;https://aileenxie.github.io/img/01.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;第一项L(yi,f(xi;w))&lt;/strong&gt;:
衡量我们的模型（分类或者回归）对第i个样本的预测值f(xi;w)和真实的标签yi之前的误差。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果是Square loss,那就是最小二乘了；&lt;/li&gt;
&lt;li&gt;如果是Hinge Loss，那就是著名的SVM了；&lt;/li&gt;
&lt;li&gt;如果是exp-Loss，那就是牛逼的 Boosting了；&lt;/li&gt;
&lt;li&gt;如果是log-Loss，那就是Logistic Regression了；&lt;/li&gt;
&lt;li&gt;不同的loss函数，具有不同的拟合特性，这个也得就具体问题具体分析的。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;第二项λΩ(w)&lt;/strong&gt;:
也就是对参数w的规则化函数Ω(w)去约束我们的模型尽量的简单。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;本文讨论的即是“规则项Ω(w)”；&lt;/li&gt;
&lt;li&gt;一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数；&lt;/li&gt;
&lt;li&gt;论文中常见的都聚集在：零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;l0范数与l1范数&#34;&gt;L0范数与L1范数&lt;/h2&gt;

&lt;h3 id=&#34;l0范数&#34;&gt;L0范数&lt;/h3&gt;

&lt;p&gt;L0范数（||W||0）是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。换句话说，让参数W是稀疏的。&lt;/p&gt;

&lt;h3 id=&#34;l1范数&#34;&gt;L1范数&lt;/h3&gt;

&lt;p&gt;L1范数（||W||1）是指向量中各个元素绝对值之和，也有个美称叫&lt;strong&gt;“稀疏规则算子”（Lasso regularization）&lt;/strong&gt;。L1范数会使权值稀疏，它是L0范数的最优凸近似。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tips: 任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;为什么不用l0-而用l1&#34;&gt;为什么不用L0，而用L1？&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;是因为L0范数很难优化求解（NP难问题）；&lt;/li&gt;
&lt;li&gt;是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。&lt;/li&gt;
&lt;li&gt;总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;为什么要稀疏&#34;&gt;为什么要稀疏？&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;特征选择(Feature Selection)：去掉没有信息的特征，及将对应权重置0，防止无用特征对测试新样本的干扰；&lt;/li&gt;
&lt;li&gt;可解释性(Interpretability)：如最初有1000个特征，回归模型：y=w1*x1+w2*x2+…+w1000*x1000+b，通过学习，如果最后学习到只有5个非零的wi，那么就可以说影响患病率的主要就是这5个特征，医生就好分析多了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;l2范数&#34;&gt;L2范数&lt;/h2&gt;

&lt;p&gt;L2范数（||W||2）是指向量各元素的平方和然后求平方根。它有两个美称，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减”（weight decay）它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。与L1范数不同，它不会让它等于0，而是&lt;strong&gt;接近于0&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;l2范数的好处&#34;&gt;L2范数的好处：&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力。&lt;/li&gt;
&lt;li&gt;从优化计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;condition-number&#34;&gt;Condition number&lt;/h3&gt;

&lt;p&gt;优化有两大难题，一是：局部最小值，二是：ill-condition病态问题。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ill-condition病态：假设我们有个方程组AX=b，我们需要求解X。如果A或者b稍微的改变，会使得X的解发生很大的改变，那么这个方程组系统就是ill-condition的，反之就是well-condition的。&lt;/li&gt;
&lt;li&gt;condition number：用来衡量ill-condition系统的可信度的，即输入发生微小变化时，输出会发生多大变化。值越小越好。
如果方阵A是非奇异的，那么A的condition number定义为：
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_76.jpg&#34; alt=&#34;&#34; /&gt;
如果方阵A是奇异的，那么A的condigion number正无穷大。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;l2为什么能处理condition-number不好的情况&#34;&gt;L2为什么能处理condition number不好的情况？&lt;/h3&gt;

&lt;p&gt;因为目标函数如果是二次的，对于线性回归来说，那实际上是有解析解的，求导并令导数等于零即可得到最优解为：
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_81.jpg&#34; alt=&#34;&#34; /&gt;
如果&lt;strong&gt;当我们的样本X的数目比每个样本的维度还要小的时候，矩阵XTX将会不是满秩的，也就是XTX会变得不可逆&lt;/strong&gt;，所以w*就没办法直接计算出来了。或者更确切地说，将会有无穷多个解（因为我们方程组的个数小于未知数的个数）。总而言之，我们过拟合了。
但如果加上L2规则项，就变成了下面这种情况，就可以直接求逆了(？？？)：
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_84.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;要得到这个解，我们通常并不直接求矩阵的逆，而是通过解线性方程组的方式（例如高斯消元法）来计算。&lt;/li&gt;
&lt;li&gt;考虑没有规则项的时候，也就是λ=0的情况，如果矩阵XTX的 condition number 很大的话，解线性方程组就会在数值上相当不稳定，而这个规则项的引入则可以改善condition number。&lt;/li&gt;
&lt;li&gt;如果使用迭代优化的算法，condition number太大还会拖慢迭代收敛的速度。规则项从优化的角度来看，实际上是将目标函数变成λ-strongly convex（λ强凸）的了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;强凸&#34;&gt;强凸&lt;/h3&gt;

&lt;p&gt;就是convex 可以保证函数在任意一点都处于它的一阶泰勒函数之上，而strongly convex可以保证函数在任意一点都存在一个非常漂亮的二次下界quadratic lower bound。
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_92.jpg&#34; alt=&#34;&#34; /&gt;
正如上面分析的那样，如果f(w)在全局最小点w*周围是非常平坦的情况的话，我们有可能会找到一个很远的点。但如果我们有“强凸”的话，就能对情况做一些控制，我们就可以得到一个更好的近似解。&lt;/p&gt;

&lt;h3 id=&#34;l1和l2差别&#34;&gt;L1和L2差别&lt;/h3&gt;

&lt;h4 id=&#34;1-下降速度&#34;&gt;1.&lt;strong&gt;下降速度&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;我们将权值参数以L1或者L2的方式放到代价函数里面去。然后模型就会尝试去最小化这些权值参数。而这个最小化就像一个下坡的过程，L1和L2的差别就在于这个“坡”不同：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;L1就是按绝对值函数的“坡”下降的&lt;/li&gt;

&lt;li&gt;&lt;p&gt;L2是按二次函数的“坡”下降。&lt;/p&gt;

&lt;p&gt;所以实际上在0附近，L1的下降速度比L2的下降速度要快。所以会非常快得降到0。
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_104.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-模型空间的限制-l1-regularization-能产生稀疏性-而l2-regularization-不行&#34;&gt;2.&lt;strong&gt;模型空间的限制(L1-regularization 能产生稀疏性，而L2-regularization 不行)：&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;L1和L2规则化的代价函数形式如下：
  &lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_109.jpg&#34; alt=&#34;&#34; /&gt;
  在(w1, w2)平面上可以画出目标函数的等高线，而约束条件则成为平面上半径为C的一个 norm ball 。等高线与 norm ball 首次相交的地方就是最优解：
  &lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_111.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;L1-ball 与L2-ball 的不同就在于：
L1. 在和每个坐标轴相交的地方都有“角”出现，而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性;
L2. 没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;总结：&lt;/strong&gt;L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;核范数&#34;&gt;核范数&lt;/h2&gt;

&lt;p&gt;核范数||W||*是指矩阵奇异值的和，英文称呼叫Nuclear Norm。用来约束Low-Rank（低秩）。&lt;/p&gt;

&lt;h3 id=&#34;约束rank-w-与核范数有何关系&#34;&gt;约束rank（w）与核范数有何关系？&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;因为rank()是&lt;strong&gt;非凸的&lt;/strong&gt;，在优化问题里面很难求解，那么就需要寻找它的凸近似来近似它了。rank(w)的凸近似就是核范数||W||*。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;低秩的应用&#34;&gt;低秩的应用&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;矩阵填充(Matrix Completion)&lt;/li&gt;
&lt;li&gt;鲁棒PCA（鲁棒：只是假设它的噪声是稀疏的）&lt;/li&gt;
&lt;li&gt;背景建模&lt;/li&gt;
&lt;li&gt;变换不变低秩纹理（TILT）
具体讲解见&lt;a href=&#34;https://blog.csdn.net/zouxy09/article/details/24972869&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;参考文章&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;规则化参数的选择&#34;&gt;规则化参数的选择&lt;/h2&gt;

&lt;p&gt;重新审视我们的目标函数：
&lt;img src=&#34;https://aileenxie.github.io/img/02l_norm_132.jpg&#34; alt=&#34;&#34; /&gt;
里面除了loss和规则项两块外，还有一个参数λ，叫hyper-parameters（超参）。它主要是平衡loss和规则项这两项的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;λ越大，就表示规则项要比模型训练误差更重要，也就是相比于要模型拟合我们的数据，我们更希望我们的模型能满足我们约束的Ω(w)的特性。&lt;/li&gt;
&lt;li&gt;λ越小，就表示希望输出与期待值误差最小（回归曲线尽量过所有点，就会过拟合）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;调参经验&#34;&gt;调参经验&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;如Hinton大哥的那篇A Practical Guide to Training RestrictedBoltzmann Machines等等；&lt;/li&gt;
&lt;li&gt;通过分析我们的模型来选择：
在训练之前，我们大概计算下这时候的loss项的值是多少？Ω(w)的值是多少？然后针对他们的比例来确定我们的λ，这种启发式的方法会缩小我们的搜索空间。&lt;/li&gt;
&lt;li&gt;交叉验证Cross validation：
先把我们的训练数据库分成几份，然后取一部分做训练集，一部分做测试集，然后选择不同的λ用这个训练集来训练N个模型，然后用这个测试集来测试我们的模型，取N模型里面的测试误差最小对应的λ来作为我们最终的λ。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Hugo快速搭建博客</title>
      <link>https://aileenxie.github.io/2018/01hugoblog/</link>
      <pubDate>Fri, 05 Oct 2018 21:52:20 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/01hugoblog/</guid>
      <description>

&lt;p&gt;简单记录一下mac下用&lt;a href=&#34;https://gohugo.io/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Hugo&lt;/a&gt;搭建博客的过程，以便日后查阅。感谢&lt;a href=&#34;https://blog.renyijiu.com/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;renyijiu&lt;/a&gt;的安利和帮助。&lt;/p&gt;

&lt;h2 id=&#34;hugo&#34;&gt;Hugo&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一个用Go语言写的静态网站生成器&lt;/li&gt;
&lt;li&gt;能把markdown转变成静态网页&lt;/li&gt;
&lt;li&gt;内置web服务期，便于本地草稿调试&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装-hugo&#34;&gt;安装 Hugo&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直接用Homebrew安装&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install hugo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;完成之后查看版本，我目前装的是0.49&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;创建一个新站点&#34;&gt;创建一个新站点&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;到你的目录下找个喜欢的地方执行语句&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo new site myblog
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;会在当前目录生成一个叫“myblog”的目录，里面包含若干文件夹和一个config.toml文件:&lt;/p&gt;

&lt;p&gt;▸ archetypes/&lt;/p&gt;

&lt;p&gt;▸ content/ -&amp;gt;你写的markdown文章&lt;/p&gt;

&lt;p&gt;▸ layouts/ -&amp;gt;网站的模板文件&lt;/p&gt;

&lt;p&gt;▸ static/ -&amp;gt;放的是一些图片、css、js等资源&lt;/p&gt;

&lt;p&gt;▸ data/&lt;/p&gt;

&lt;p&gt;▸ themes/ -&amp;gt;放的是你之后添加的主题&lt;/p&gt;

&lt;p&gt;config.toml -&amp;gt;网站的配置文件&lt;/p&gt;

&lt;h2 id=&#34;添加主题&#34;&gt;添加主题&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进入目录页&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd myblog
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;初始化为git项目，方便之后放入github或者任何仓库进行版本管理&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git init
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;添加主题, 以LeaveIt为例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git submodule add  https://github.com/liuzc/LeaveIt.git themes/LeaveIt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后会在themes/目录下看到你添加的主题。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;修改配置文件(直接打开config.toml文件修改也是一样的)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#39;theme = &amp;quot;LeaveIt&amp;quot;&#39; &amp;gt;&amp;gt; config.toml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hugo中有很多可供选择的&lt;a href=&#34;https://themes.gohugo.io/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;主题&lt;/a&gt;，选一个你喜欢的，复制链接替换上面的主题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;添加第一篇博客&#34;&gt;添加第一篇博客&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在myblog目录下运行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo new posts/my-first-post.md
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;会在content/posts目录下生成一个my-first-post.md的文件，文件初始会有&amp;rdquo;title&amp;rdquo;(文章标题)、&amp;rdquo;date&amp;rdquo;（文章时间）、&amp;rdquo;draft&amp;rdquo;（是否是草稿）几个字段内容。之后你要写的内容以markdown写在后面即可，这里我们可以先不管。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;【tips】: 刚开始我在这步运行报错，查了资料发现是hugo版本问题，需要更新到0.48以上，如果装的版本旧了，手动更新一下：&lt;/b&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew update
brew upgrade hugo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;启动web服务器本地调试-看看效果&#34;&gt;启动web服务器本地调试（看看效果）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在myblog目录下运行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo server
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;访问：&lt;a href=&#34;http://localhost:1313/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://localhost:1313/&lt;/a&gt;
可以看到博客的效果，值得一提的是，前面生成的.md文档里&amp;rdquo;draft&amp;rdquo;设置为&amp;rdquo;true&amp;rdquo;的，无法被看到。想要看到作为草稿的文章，记得加&amp;rdquo;-D&amp;rdquo;参数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo server -D
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;调整你的主题&#34;&gt;调整你的主题&lt;/h2&gt;

&lt;p&gt;按照所用主题的例子修改你的config.toml文件.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;公共的部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;baseURL = &amp;quot;https://example.org/&amp;quot;
languageCode = &amp;quot;en-us&amp;quot;
title = &amp;quot;My New Hugo Site&amp;quot;
theme = &amp;quot;ananke&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;所用主题的定制部分参考主题介绍，如LeaveIt的config.toml中的头像配置  &lt;code&gt;avatar = &amp;quot;/images/me/avatar.jpeg&amp;quot;&lt;/code&gt;把你想要的头像按照/images/meavatar.jpeg格式放到&lt;strong&gt;static&lt;/strong&gt;目录下（注意不是项目根目录）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;利用hugo生成静态页面&#34;&gt;利用Hugo生成静态页面&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在myblog目录下运行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;会自动生成/刷新&lt;strong&gt;public&lt;/strong&gt;目录，之后每次修改过markdown文件或改过主题，都要重新运行&lt;code&gt;hugo&lt;/code&gt;命令以更新public目录下的静态文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;【tips】:本地调试的时候不需要运行&lt;code&gt;hugo&lt;/code&gt;,修改保存后会直接更新在页面上，但public下的静态文件是没有被更新的。&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;将public目录代码放到github上&#34;&gt;将public目录代码放到Github上&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;github上新建一个项目&amp;rdquo;blog&amp;rdquo;&lt;/li&gt;
&lt;li&gt;复制项目ssh链接地址: 如git@github.com:xxx/blog.git&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确保已上传ssh-key，进入本地myblog项目的public目录初始化git并添加远端仓库&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd public
git init
git remote add origin git@github.com:xxx/blog.git
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;提交你public下的代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git add .
git commit -m &#39;initial commit.&#39;
git push origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;设置blog项目的&amp;rdquo;Repository name&amp;rdquo;为&amp;rdquo;xxx.github.io&amp;rdquo;(xxx是你的github用户名），通过github的page功能，你的博客就可以通过&lt;a href=&#34;https://xxx.github.io/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://xxx.github.io/&lt;/a&gt;直接访问。（只提交public目录即可直接访问不用再做跳转。）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;整个过程到此结束，之后的博客更新就是直接修改content/目录下的markdown文件，然后执行&lt;code&gt;hugo&lt;/code&gt;后push更新到github。大功告成！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://aileenxie.github.io/about/</link>
      <pubDate>Fri, 05 Oct 2018 13:01:36 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/about/</guid>
      <description>

&lt;h3 id=&#34;我&#34;&gt;我&lt;/h3&gt;

&lt;p&gt;自动化测试跨界机器学习的工作后女研究僧，90后，爱学习爱生活&lt;/p&gt;

&lt;h3 id=&#34;博客&#34;&gt;博客&lt;/h3&gt;

&lt;p&gt;记录一些学习笔记和心得感悟&lt;/p&gt;

&lt;!-- ### 用过的 --&gt;

&lt;!-- + Java/Groovy+Spock --&gt;

&lt;!-- + Ruby+Cucumber+Capybara --&gt;

&lt;!-- + Selenium/Appium/Jmeter --&gt;

&lt;!-- + MySQL/PostgreSQL --&gt;

&lt;!-- + Git --&gt;

&lt;!-- ### 在学的 --&gt;

&lt;!-- 机器学习、深度学习、计算机视觉相关 --&gt;

&lt;!-- + Python --&gt;

&lt;!-- + Pytorch/TensorFlow --&gt;

&lt;!-- + RNN/CNN/DNN --&gt;

&lt;!-- + ...  --&gt;
</description>
    </item>
    
    <item>
      <title>New Start</title>
      <link>https://aileenxie.github.io/2018/00first-post/</link>
      <pubDate>Fri, 05 Oct 2018 13:01:24 +0800</pubDate>
      
      <guid>https://aileenxie.github.io/2018/00first-post/</guid>
      <description>

&lt;p&gt;重新回到学校一个月，第一个国庆避开人山人海，在上海安安心心休息了几天。&lt;/p&gt;

&lt;p&gt;之前工作的时候一直想要搭一个博客，把每天零零碎碎记录的笔记整理出来放在一起，但一直没能着手开始行动（大概是又忙又懒。。）直到笔记随手记了一大堆，越来越不想整理。&lt;/p&gt;

&lt;p&gt;回到学校自由时间多了很多，又在学习新东西，想着这是个好的时机开始写博客，终于在这个国庆开始了这项活动。&lt;/p&gt;

&lt;h3 id=&#34;关于笔记&#34;&gt;关于笔记&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;最开始一年我用的ubuntu系统，被安利了&lt;strong&gt;cherrytree&lt;/strong&gt;，试用了一下，马上被这种可以“遍地开花”随手快速记录的树状结构笔记软件所吸引。
那年我刚工作，又是从通信跨到互联网行业，很多东西对我来说都是新知识：数据库(Mysql/Postgres)、编程语言（JAVA/Groov/Python)、测试框架（Spock/Selenium/Appium/rf/jmeter)、版本管理系统（Git）、持续集成（Gradle/Jenkins）包括Linux系统本身&amp;hellip; 用cherrytree记了相当多的笔记，这一年也是我收获颇丰的一年。&lt;/li&gt;
&lt;li&gt;第二年换了macOS系统，cherrytree用不了（用模拟器打开页面很丑），先后换了有道云笔记，为知笔记，最后定格在了bootsnote（页面简洁好看，支持markdown和snippet）。又陆续做了关于ruby系测试框架（Cucumber/Capybara）、mac系统等的笔记。直到开学，我作为测试开发的工作告一段落。笔记也就此暂停。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;关于博客&#34;&gt;关于博客&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;终于展开新的研究生生活，投身于机器学习、深度学习和计算机视觉方向研究。有种可以大展拳脚的感觉略兴奋。从开学前到现在，看过了CS229吴恩达的机器学习基础课程，CS231n斯坦福卷积神经网络课程，学了pytorch框架，开始看导师给的paper。最初看的很细致，还做了手写的笔记，现在想来还是要有个地方集中放置一下，就从现在开始重新规划一下之后的笔记。预计会放一些paper的阅读笔记，学习的知识点，或许是任何想记下来的东西吧hhh&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;七天假期马上要过去啦，搭好了博客算是一个很好的开始，希望能我好好充实这个博客，记录整个研究生阶段以及未来和以后更远更远的学习旅程，(๑•̀ㅂ•́)و✧加油！！&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>