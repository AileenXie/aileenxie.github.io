<!DOCTYPE html>
<html lang="ch-cn">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Aileen.Xie">
  
  
  
  <link rel="prev" href="https://aileenxie.github.io/2018/04txf/" />
  
  <link rel="canonical" href="https://aileenxie.github.io/2018/05fdr/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           FDR与BH过程 | Aileen&#39;s Blog
       
  </title>
  <meta name="title" content="FDR与BH过程 | Aileen&#39;s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://aileenxie.github.io"
    },
    "articleSection" : "posts",
    "name" : "FDR与BH过程",
    "headline" : "FDR与BH过程",
    "description" : "--  最近导师让看的paper里用到了FDR的理念，借这个机会把FDR相关概念理解了一遍，整理出来。
统计相关基础知识 假设检验 假设检验的基本思想是小概率反证法思想。小概率思想是指小概率事件（P&lt;0.01或P&lt;0.05）在一次试验中基本上不会发生。反证法思想是先提出假设(检验假设H0)，再用适当的统计方法确定假设成立的可能性大小，如可能性小，则认为假设不成立，若可能性大，则还不能认为假设不成立。
P值 即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法（t检验，Z检验，卡方检验，F检验等等）所得到的P 值，一般以 P&lt;0.05 为有统计学差异， P&lt;0.01 为有显著统计学差异，P&lt;0.001 为有极其显著的统计学差异。其含义是样本间的差异由抽样误差所致的概率小于0.05 、0.01、0.001。实际上，P值不能赋予数据任何重要性，只能说明某事件发生的几率。
给定显著性水准alpha时，可得出对应的拒绝域；根据当前试验，可以计算出P值。当P值越小时，表示此时试验得到的统计量t越落在拒绝域。因此基于P值的结果等价于基于t值的结果。因此，P值越小，拒绝原假设的信心越大。 原假设(H0) &amp; 备择假设(H1)  原假设（又叫零假设）是在一次试验中有绝对优势出现的事件 备择假设（又叫备选假设、对立假设）在一次试验中不易发生(或几乎不可能发生)的事件。  因此，在进行单侧检验时，最好把原假设取为预想结果的反面，即把希望证明的命题放在备择假设上。
一类错误 &amp; 二类错误  第一类错误（假阳性）又称“Ⅰ型错误”、“拒真错误”，是指拒绝了实际上成立的、正确的假设，为“弃真”的错误，其概率通常用α（显著性水平）表示。 第二类错误（假阴性）又称“口错误”、“纳伪错误”、“第Ⅱ型错误”。假设检验术语。与“第一类错误”相对。在零假设H0本来不真的情况下，检验统计量的观测值落入接受域而接受Ho而犯的错误。用字母β表示。   🌰举个栗子 为了帮助理解，我编了个例子。
【例子一】小白五感超群，他自称能够辨别一杯白咖啡是先倒入的牛奶还是先倒入的咖啡。为了验证这个说法，我们进行一组实验。 实验内容：放5杯咖啡，让小白品尝并说出每一杯咖啡是先加奶还是先加咖啡。靠猜答对5杯咖啡的概率\(P=(\frac{1}{2})^{5}\approx 0.031=3.1\%\)。假设显著性水平（阈值）设为5%：
 H0：小白辨别咖啡是靠猜的 H1：小白辨别咖啡不是靠猜的（即小白有能力辨别）  试验结果是5杯咖啡都被成功辨别。此事件P = 3.1% &lt; 5%，故可以拒绝原假设，承认小白能够辨别白咖啡。但有3.1%的可能判断错误（I类错误），因为有3.1%的可能小白就是靠猜的。可以通过增加咖啡杯数来降低P值（靠猜全答对的难度越来越高），这样拒绝原假设的自信度就越高。
多重假设检验校正 多次检验导致的大量假阳性：如果检验一次，犯错的概率是5%；检验10000次，犯错的次数就是500次，即额外多出了500次差异的结论（即 使实际没有差异）。
结合例子🌰说就是：假设一人品咖啡靠猜对概率是5%，10000个人来品咖啡就会有500个人靠猜来答对，如果阈值还设为5%的话，这500个人都被判为是有能力辨别咖啡能力的人，但是明明他们都是靠猜的啊！！！那么这就有500个一类错误。
所以当同一个数据集有n次（n&gt;=2）假设检验时，要做多重假设检验校正。这里讨论Bonferroni校正和FDR校正两种P值校正方法。
Bonferroni —— “最简单严厉的方法” 如果检验1000次，我们就将阈值设定为5%/1000=0.005%；即使检验1000次，犯错误的概率还是保持在0.005%×1000 = 5%。最终使得预期犯错误的次数不到1次，抹杀了一切假阳性的概率。 该方法虽然简单，但是检验过于严格，导致最后找不到显著表达的蛋白（假阴性）。
结合例子🌰说就是：10000人品咖啡应当相应地降低阈值，设成5%/10000=0.0005%（相对应的，增加咖啡杯数，比如让一个人分辨15杯咖啡，这用猜的就很难全对了吧！！！），那么这10000个人只会有5个人能靠猜来答对，大大降低了伪能力者（I类错误）。但是！！！15杯咖啡让真正有辨别能力的小白来喝，也会有味觉疲劳、品错的时候啊。这时候就出现了II类错误（假阴性）——判别小白没有鉴别能力，是靠猜的&hellip;
FDR —— “比较温和的方法校正P值” 假阳性错误控制法是Benjamini于1995年提出的一种方法。基本原理是通过控制FDR值来决定P值的值域。相对Bonferroni来说，FDR用比较温和的方法对p值进行了校正。其试图在假阳性和假阴性间达到平衡，将假/真阳性比例控制到一定范围之内。例如，如果检验1000次，我们设定的阈值为0.05（5%），那么无论我们进行多少次实验，这些实验结果出现假阳性的概率保持在5%之内，这就叫FDR＜5%。
Q值 衡量错误发现率FDR（false discovery rates）的指标。\(FDR=\frac{I型错误数}{总拒绝数} = \frac{V}{R}=Q,R=0时Q=0\)",
    "inLanguage" : "ch-cn",
    "author" : "Aileen.Xie",
    "creator" : "Aileen.Xie",
    "publisher": "Aileen.Xie",
    "accountablePerson" : "Aileen.Xie",
    "copyrightHolder" : "Aileen.Xie",
    "copyrightYear" : "2018",
    "datePublished": "2018-11-19 19:59:46 &#43;0800 CST",
    "dateModified" : "2018-11-19 19:59:46 &#43;0800 CST",
    "url" : "https://aileenxie.github.io/2018/05fdr/",
    "wordCount" : "76",
    "keywords" : [ "统计分析", "Aileen&#39;s Blog"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://aileenxie.github.io">Aileen&#39;s Blog</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://aileenxie.github.io">Aileen&#39;s Blog</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">FDR与BH过程</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://aileenxie.github.io" rel="author">Aileen.Xie</a> with ♥ 
                <span class="post-time">
                on <time datetime=2018-11-19 itemprop="datePublished">November 19, 2018</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://aileenxie.github.io/categories/%E5%AD%A6%E4%B9%A0-%E7%AC%94%E8%AE%B0/"> 学习 · 笔记 </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          

<!-- <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script> -->

<script type="text/javascript" src="https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=default"></script>

<p>最近导师让看的paper里用到了FDR的理念，借这个机会把FDR相关概念理解了一遍，整理出来。</p>

<h2 id="统计相关基础知识">统计相关基础知识</h2>

<h3 id="假设检验">假设检验</h3>

<p>假设检验的基本思想是<strong>小概率反证法</strong>思想。小概率思想是指小概率事件（P&lt;0.01或P&lt;0.05）在一次试验中基本上不会发生。反证法思想是先提出假设(检验假设H0)，再用适当的统计方法确定假设成立的可能性大小，如可能性小，则认为假设不成立，若可能性大，则还不能认为假设不成立。</p>

<h3 id="p值">P值</h3>

<p>即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法（<a href="https://aileenxie.github.io/2018/04txf/" rel="nofollow noreferrer" target="_blank">t检验，Z检验，卡方检验，F检验</a>等等）所得到的P 值，一般以 P&lt;0.05 为有统计学差异， P&lt;0.01 为有显著统计学差异，P&lt;0.001 为有极其显著的统计学差异。其含义是样本间的差异由抽样误差所致的概率小于0.05 、0.01、0.001。实际上，P值不能赋予数据任何重要性，只能说明某事件发生的几率。</p>

<p>给定显著性水准alpha时，可得出对应的拒绝域；根据当前试验，可以计算出P值。当P值越小时，表示此时试验得到的统计量t越落在拒绝域。因此基于P值的结果等价于基于t值的结果。因此，<strong>P值越小，拒绝原假设的信心越大</strong>。
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="https://ws2.sinaimg.cn/large/006tNbRwly1fxdp9u4qhnj30ji0fsju3.jpg" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></p>

<h3 id="原假设-h0-备择假设-h1">原假设(H0) &amp; 备择假设(H1)</h3>

<ul>
<li>原假设（又叫零假设）是在一次试验中有绝对优势出现的事件</li>
<li>备择假设（又叫备选假设、对立假设）在一次试验中不易发生(或几乎不可能发生)的事件。</li>
</ul>

<p>因此，在进行单侧检验时，最好把<strong>原假设</strong>取为预想结果的<strong>反面</strong>，即把希望证明的命题放在备择假设上。</p>

<h3 id="一类错误-二类错误">一类错误 &amp; 二类错误</h3>

<ul>
<li>第一类错误（假阳性）又称“Ⅰ型错误”、“拒真错误”，是指拒绝了实际上成立的、正确的假设，为“弃真”的错误，其概率通常用α（显著性水平）表示。</li>
<li>第二类错误（假阴性）又称“口错误”、“纳伪错误”、“第Ⅱ型错误”。假设检验术语。与“第一类错误”相对。在零假设H0本来不真的情况下，检验统计量的观测值落入接受域而接受Ho而犯的错误。用字母β表示。
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="https://ws1.sinaimg.cn/large/006tNbRwly1fxdo1qahx9j30jn05qgo2.jpg" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure></li>
</ul>

<h4 id="举个栗子">🌰举个栗子</h4>

<hr />

<p>为了帮助理解，我编了个例子。</p>

<p>【例子一】小白五感超群，他自称能够辨别一杯白咖啡是先倒入的牛奶还是先倒入的咖啡。为了验证这个说法，我们进行一组实验。
实验内容：放5杯咖啡，让小白品尝并说出每一杯咖啡是先加奶还是先加咖啡。靠猜答对5杯咖啡的概率\(P=(\frac{1}{2})^{5}\approx 0.031=3.1\%\)。假设显著性水平（阈值）设为5%：</p>

<ul>
<li>H0：小白辨别咖啡是靠猜的</li>
<li>H1：小白辨别咖啡不是靠猜的（即小白有能力辨别）</li>
</ul>

<p>试验结果是5杯咖啡都被成功辨别。此事件P = 3.1% &lt; 5%，故可以拒绝原假设，承认小白能够辨别白咖啡。但有3.1%的可能判断错误（I类错误），因为有3.1%的可能小白就是靠猜的。可以通过增加咖啡杯数来降低P值（靠猜全答对的难度越来越高），这样拒绝原假设的自信度就越高。</p>

<h2 id="多重假设检验校正">多重假设检验校正</h2>

<p>多次检验导致的大量假阳性：如果检验一次，犯错的概率是5%；检验10000次，犯错的次数就是500次，即额外多出了500次差异的结论（即
使实际没有差异）。</p>

<p>结合例子🌰说就是：假设一人品咖啡靠猜对概率是5%，10000个人来品咖啡就会有500个人靠猜来答对，如果阈值还设为5%的话，这500个人都被判为是有能力辨别咖啡能力的人，但是明明他们都是靠猜的啊！！！那么这就有500个一类错误。</p>

<p>所以当同一个数据集有n次（n&gt;=2）假设检验时，要做多重假设检验校正。这里讨论Bonferroni校正和FDR校正两种P值校正方法。</p>

<h3 id="bonferroni-最简单严厉的方法">Bonferroni —— “最简单严厉的方法”</h3>

<p>如果检验1000次，我们就将阈值设定为5%/1000=0.005%；即使检验1000次，犯错误的概率还是保持在0.005%×1000 = 5%。最终使得预期犯错误的次数不到1次，抹杀了一切假阳性的概率。
该方法虽然简单，但是检验过于严格，导致最后找不到显著表达的蛋白（假阴性）。</p>

<p>结合例子🌰说就是：10000人品咖啡应当相应地降低阈值，设成5%/10000=0.0005%（相对应的，增加咖啡杯数，比如让一个人分辨15杯咖啡，这用猜的就很难全对了吧！！！），那么这10000个人只会有5个人能靠猜来答对，大大降低了伪能力者（I类错误）。但是！！！15杯咖啡让真正有辨别能力的小白来喝，也会有味觉疲劳、品错的时候啊。这时候就出现了II类错误（假阴性）——判别小白没有鉴别能力，是靠猜的&hellip;</p>

<h3 id="fdr-比较温和的方法校正p值">FDR —— “比较温和的方法校正P值”</h3>

<p>假阳性错误控制法是Benjamini于1995年提出的一种方法。基本原理是通过控制FDR值来决定P值的值域。相对Bonferroni来说，FDR用比较温和的方法对p值进行了校正。其试图在假阳性和假阴性间达到平衡，将假/真阳性比例控制到一定范围之内。例如，如果检验1000次，我们设定的阈值为0.05（5%），那么无论我们进行多少次实验，这些实验结果出现假阳性的概率保持在5%之内，这就叫FDR＜5%。</p>

<h4 id="q值">Q值</h4>

<p>衡量错误发现率FDR（false discovery rates）的指标。\(FDR=\frac{I型错误数}{总拒绝数} = \frac{V}{R}=Q,R=0时Q=0\)</p>

<h4 id="bh法">BH法</h4>

<p>那么我们怎么从p value 来估算FDR呢，人们设计了几种不同的估算模型。其中使用最多的是Benjamini and Hochberg方法，简称BH法。虽然这个估算公式并不够完美，但是也能解决大部分的问题，主要还是简单好用！</p>

<ol>
<li><p>将所有P-value升序排列.P-value记为P，P-value的序号记为i，P-value的总数记为m</p></li>

<li><p>FDR(i)=P(i)*m/i</p></li>

<li><p>根据i的取值从大到小，依次执行FDR(i)=min{FDR(i),FDR(i+1)}</p></li>
</ol>

<p>注：实际上，BH法的原始算法是找到一个最大的i，满足P≤i/m*FDR阈值，此时，所有小于i的数据就都可以认为是显著的。在实践中，为了能够在比较方便的用不同的FDR阈值对数据进行分析，采用了步骤3里的方法。这个方法可以保证，不论FDR阈值选择多少，都可以直接根据FDR的数值来直接找到所有显著的数据。</p>

<p>下面我们以一个包含10个数据的例子来看一下FDR计算的过程
<figure><img src="/images/ring.svg" data-sizes="auto" data-src="https://ws1.sinaimg.cn/large/006tNbRwly1fxds9xp58qj30jm0b90wm.jpg" alt="" class="lazyload"><figcaption class="image-caption"></figcaption></figure>
在这个例子中，第一列是原始的P-value，第二列是排序后的序号，第三列是根据P-value校正得到的初始FDR，第四列是最终用于筛选数据的FDR数值。如果我们设定FDR&lt;0.05，那么绿色高亮的两个数据就是最终分析认为显著的数据。</p>

<hr />

<p>参考文章</p>

<p><a href="https://www.plob.org/article/13796.html" rel="nofollow noreferrer" target="_blank">差异表达分析之FDR</a></p>

<p><a href="https://blog.csdn.net/zhu_si_tao/article/details/71077703" rel="nofollow noreferrer" target="_blank">多重假设检验与Bonferroni校正、FDR校正</a></p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Aileen.Xie </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://aileenxie.github.io/2018/05fdr/>https://aileenxie.github.io/2018/05fdr/</span>
            </p>
            
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://aileenxie.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/">
                    #统计分析</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://aileenxie.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://aileenxie.github.io/2018/04txf/" class="prev" rel="prev" title="t分布, 卡方x分布，F分布"><i class="iconfont icon-left"></i>&nbsp;t分布, 卡方x分布，F分布</a>
         
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2017 - 2018</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            
            <span class="author" itemprop="copyrightHolder"><a href="https://aileenxie.github.io">Aileen.Xie</a> </span> 
         

         
		  
    </div>
</footer>












    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
